<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>爬虫 | thr's blog</title><meta name="author" content="thr"><meta name="copyright" content="thr"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="爬虫1. 相关概念介绍 解释1：通过一个程序，根据 Url 进行爬取网页，获取有用的信息 解释2：使用程序模拟浏览器，去向服务器发送请求，获取响应信息  1.1 爬虫核心？ 爬取网页 解析数据(重点) 难点：爬虫与反爬虫之间的博弈  1.2 爬虫的用途 数据分析&#x2F;人工数据集 社交软件冷启动 舆情监控 竞争对手监控  1.3 爬虫分类 通用爬虫(不学) 功能：访问网页-&gt;抓取数据-&amp;">
<meta property="og:type" content="article">
<meta property="og:title" content="爬虫">
<meta property="og:url" content="https://tangsmallrong.github.io/2023/11/18/Spider/index.html">
<meta property="og:site_name" content="thr&#39;s blog">
<meta property="og:description" content="爬虫1. 相关概念介绍 解释1：通过一个程序，根据 Url 进行爬取网页，获取有用的信息 解释2：使用程序模拟浏览器，去向服务器发送请求，获取响应信息  1.1 爬虫核心？ 爬取网页 解析数据(重点) 难点：爬虫与反爬虫之间的博弈  1.2 爬虫的用途 数据分析&#x2F;人工数据集 社交软件冷启动 舆情监控 竞争对手监控  1.3 爬虫分类 通用爬虫(不学) 功能：访问网页-&gt;抓取数据-&amp;">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://tangsmallrong.github.io/img/avatar.jpg">
<meta property="article:published_time" content="2023-11-18T02:41:20.000Z">
<meta property="article:modified_time" content="2023-11-18T09:04:21.364Z">
<meta property="article:author" content="thr">
<meta property="article:tag" content="spider">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://tangsmallrong.github.io/img/avatar.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://tangsmallrong.github.io/2023/11/18/Spider/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: thr","link":"链接: ","source":"来源: thr's blog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '爬虫',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-11-18 17:04:21'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.0.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/./img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">8</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="thr's blog"><span class="site-name">thr's blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">爬虫</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-11-18T02:41:20.000Z" title="发表于 2023-11-18 10:41:20">2023-11-18</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-11-18T09:04:21.364Z" title="更新于 2023-11-18 17:04:21">2023-11-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/python/">python</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">16.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>72分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="爬虫"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="post-content" id="article-container"><h1 id="爬虫"><a href="#爬虫" class="headerlink" title="爬虫"></a>爬虫</h1><h2 id="1-相关概念介绍"><a href="#1-相关概念介绍" class="headerlink" title="1. 相关概念介绍"></a>1. 相关概念介绍</h2><ul>
<li><strong>解释1</strong>：通过一个程序，根据 Url 进行爬取网页，获取有用的信息</li>
<li><strong>解释2</strong>：使用程序模拟浏览器，去向服务器发送请求，获取响应信息</li>
</ul>
<h3 id="1-1-爬虫核心？"><a href="#1-1-爬虫核心？" class="headerlink" title="1.1 爬虫核心？"></a>1.1 爬虫核心？</h3><ul>
<li><strong>爬取网页</strong></li>
<li><strong>解析数据</strong>(重点)</li>
<li>难点：爬虫与反爬虫之间的博弈</li>
</ul>
<h3 id="1-2-爬虫的用途"><a href="#1-2-爬虫的用途" class="headerlink" title="1.2 爬虫的用途"></a>1.2 爬虫的用途</h3><ul>
<li>数据分析&#x2F;人工数据集</li>
<li>社交软件冷启动</li>
<li>舆情监控</li>
<li>竞争对手监控</li>
</ul>
<h3 id="1-3-爬虫分类"><a href="#1-3-爬虫分类" class="headerlink" title="1.3 爬虫分类"></a>1.3 爬虫分类</h3><ul>
<li><strong>通用爬虫</strong>(不学)<ul>
<li>功能：访问网页-&gt;抓取数据-&gt;数据存储-&gt;数据除了-&gt;提供检索服务</li>
<li>实例：百度、google等搜索引擎</li>
<li>缺点：<ul>
<li>抓取的数据大多是无用的</li>
<li>不能根据用户的需求来精准获取数据</li>
</ul>
</li>
</ul>
</li>
<li><strong>聚焦爬虫</strong><ul>
<li>功能：根据需求，实现爬虫程序，抓取需要的数据</li>
<li>&#x3D;&#x3D;设计思路&#x3D;&#x3D;：<ul>
<li>确定要爬取的url</li>
<li>模拟浏览器通过 http 协议访问 url，获取服务器返回的 html 代码</li>
<li>解析 html 字符串</li>
</ul>
</li>
</ul>
</li>
<li><strong>增量式爬虫</strong><ul>
<li>检测网站中的数据更新情况，只会抓取网站中最新更新出来的数据</li>
</ul>
</li>
</ul>
<h3 id="1-4-反爬手段"><a href="#1-4-反爬手段" class="headerlink" title="1.4 反爬手段"></a>1.4 反爬手段</h3><ul>
<li>User-Agent：<ul>
<li>简称 UA，是一个特殊的字符串头，能识别客户使用的操作系统及版本、CPU 类型、浏览器语言、插件等等</li>
</ul>
</li>
<li>代理 IP</li>
<li>验证码访问</li>
<li>动态加载网页<ul>
<li>网站返回的是 js 数据，并不是真实的网页数据</li>
</ul>
</li>
<li>数据加密</li>
</ul>
<h2 id="2-urllib-库使用"><a href="#2-urllib-库使用" class="headerlink" title="2. urllib 库使用"></a>2. urllib 库使用</h2><h3 id="2-1-基本使用"><a href="#2-1-基本使用" class="headerlink" title="2.1 基本使用"></a>2.1 基本使用</h3><blockquote>
<p>python 本身自带，不需要安装</p>
</blockquote>
<ul>
<li><code>urllib.request.rulopen()</code> 模拟浏览器向服务器发送请求<ul>
<li>response 服务器返回的数据</li>
<li>response 的数据类型是 HttpResponse</li>
</ul>
</li>
<li>字节–&gt;字符串<ul>
<li>解码decode</li>
</ul>
</li>
<li>字符串–&gt;字节<ul>
<li>编码encode</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 urllib 获取百度首页的源码</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 定义一个 url: 就是你要访问的地址</span></span><br><span class="line">url = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 模拟浏览器向服务器发送请求</span></span><br><span class="line">response = urllib.request.urlopen(url)  <span class="comment"># 打开网址并获取响应</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 获取响应中的页面源码</span></span><br><span class="line"><span class="comment"># read 方法返回的是字节形式的二进制数据</span></span><br><span class="line"><span class="comment"># 要将二进制的数据转换为字符串</span></span><br><span class="line"><span class="comment"># 解码: 二进制--&gt;字符串  编码的格式?</span></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 打印数据</span></span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure>

<h3 id="2-2-一个类型，六个方法"><a href="#2-2-一个类型，六个方法" class="headerlink" title="2.2 一个类型，六个方法"></a>2.2 一个类型，六个方法</h3><ul>
<li><strong>response 是 HTTPResponse 类型</strong></li>
<li><strong>方法</strong><ul>
<li>read()        <ul>
<li>字节形式读取二进制 扩展：rede(5)返回前几个字节</li>
</ul>
</li>
<li>readline()  读取一行</li>
<li>readlines() 一行一行读取 直至结束</li>
<li>getcode()  获取状态吗</li>
<li>geturl()      获取url</li>
<li>getheaders() 获取headers</li>
</ul>
</li>
<li>代码：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 定义一个 url: 就是你要访问的地址</span></span><br><span class="line">url = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 模拟浏览器向服务器发送请求</span></span><br><span class="line">response = urllib.request.urlopen(url)  <span class="comment"># 打开网址并获取响应</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 一个类型和六个方法</span></span><br><span class="line"><span class="comment"># response 是 HTTPResponse 类型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(response))  <span class="comment"># &lt;class &#x27;http.client.HTTPResponse&#x27;&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.1 按照一个字节一个字节去读</span></span><br><span class="line"><span class="comment"># content = response.read()</span></span><br><span class="line"><span class="comment"># content = response.read(5)  # 返回 5 个字节</span></span><br><span class="line"><span class="comment"># print(content)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.2 读取一行</span></span><br><span class="line"><span class="comment"># content = response.readline()</span></span><br><span class="line"><span class="comment"># print(content)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.3 一行一行读, 直到读完, 但都还是字节</span></span><br><span class="line"><span class="comment"># content = response.readlines()</span></span><br><span class="line"><span class="comment"># print(content)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.4 返回状态吗 200为成功</span></span><br><span class="line"><span class="built_in">print</span>(response.getcode())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.5 返回你所访问的 url 地址</span></span><br><span class="line"><span class="built_in">print</span>(response.geturl())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.6 返回状态信息</span></span><br><span class="line"><span class="built_in">print</span>(response.getheaders())</span><br></pre></td></tr></table></figure>

<h3 id="2-3-下载"><a href="#2-3-下载" class="headerlink" title="2.3 下载"></a>2.3 下载</h3><ul>
<li>方法：<code>urlretrieve</code></li>
<li>使用：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 下载网页</span></span><br><span class="line">url_page = <span class="string">&#x27;http://www.baidu.com&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># urlretrieve 的参数, url 代表下载的路径, filename 代表下载保存的文件的名字</span></span><br><span class="line">urllib.request.urlretrieve(url_page, <span class="string">&#x27;baidu.html&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 下载图片</span></span><br><span class="line">url_img = <span class="string">&#x27;https://tse1-mm.cn.bing.net/th/id/OIP-C.Z7jHpg5FBaGIu8DETlUVrgAAAA?w=282&amp;h=159&amp;c=7&amp;r=0&amp;o=5&amp;dpr=1.3&amp;pid=1.7&#x27;</span></span><br><span class="line">urllib.request.urlretrieve(url=url_img, filename=<span class="string">&#x27;1999.png&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 下载视频 b站的貌似不行, 换个别的吧</span></span><br><span class="line">url_video = <span class="string">&#x27;https://www.bilibili.com/97a65886-83e4-4445-a64b-e089da359f0e&quot;&#x27;</span></span><br><span class="line">urllib.request.urlretrieve(url_video, <span class="string">&#x27;1999.mp4&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="2-4-请求对象的定制"><a href="#2-4-请求对象的定制" class="headerlink" title="2.4 请求对象的定制"></a>2.4 请求对象的定制</h3><ul>
<li>爬虫是模拟浏览器向服务器发送请求的过程，定制对象(UA)是一种反爬虫的手段，需要使用headers定制操作系统<ul>
<li>&#x3D;&#x3D;请求对象的定制是为了解决反爬的第一种手段&#x3D;&#x3D;</li>
</ul>
</li>
<li>找到 baidu 的 UA：<ul>
<li><code>User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69 </code></li>
</ul>
</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695954812553.png" alt="1695954812553"></p>
<ul>
<li><strong>语法</strong>：<code>request = urllib.request.Request()</code></li>
<li><strong>代码实现</strong>：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://www.baidu.com&#x27;</span>  <span class="comment"># 注意这里变成 https 了, 之后会遇到反爬UA, 返回数据不完整</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># url 的组成</span></span><br><span class="line"><span class="comment"># 协议(http/https) 主机(域名/ip地址) 端口号(80/443) 路径 参数 锚点(#)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 把 UA 写作一个字典形式</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 因为 urlopen 方法中不能存储字典, 所有 headers 不能传递进去</span></span><br><span class="line"><span class="comment"># 所以进行请求对象的定制</span></span><br><span class="line"><span class="comment"># 注意：因为参数顺序的问题, 不能直接写 url 和 headers, 中间还有一个 data, 所以我们需要关键字传参</span></span><br><span class="line">request = urllib.request.Request(url=url, headers=headers)</span><br><span class="line"><span class="comment"># 传入请求对象</span></span><br><span class="line">response = urllib.request.urlopen(request)  <span class="comment"># 成功</span></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure>

<h3 id="2-5-编解码"><a href="#2-5-编解码" class="headerlink" title="2.5 编解码"></a>2.5 编解码</h3><blockquote>
<p>大一统编码：Unicode 编码</p>
<p>所以粘贴过来的url会变成这样<code>https://www.baidu.com/s?wd=%E5%91%A8%E6%9D%B0%E4%BC%A6 </code></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695955894782.png" alt="1695955894782"></p>
</blockquote>
<h4 id="2-5-1-get-请求的-quote-方法"><a href="#2-5-1-get-请求的-quote-方法" class="headerlink" title="2.5.1 get 请求的 quote 方法"></a>2.5.1 get 请求的 quote 方法</h4><blockquote>
<p>把中文转换成unicode编码，不常用</p>
</blockquote>
<ul>
<li><strong>用法</strong>：<code>name = urllib.parse.quote(&#39;周杰伦&#39;)</code></li>
<li><strong>代码</strong>：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://www.baidu.com/s?wd=%E5%91%A8%E6%9D%B0%E4%BC%A6</span></span><br><span class="line"><span class="comment"># 需求: 获取 https://www.baidu.com/s?wd=周杰伦 的网页源码</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://www.baidu.com/s?wd=&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求对象的定制是为了解决反爬的第一种手段</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将周杰伦三个字变成 unicode 编码的格式</span></span><br><span class="line"><span class="comment"># 需要依赖于 urllib.parse</span></span><br><span class="line">name = urllib.parse.quote(<span class="string">&#x27;周杰伦&#x27;</span>)</span><br><span class="line">url = url + name</span><br><span class="line"><span class="built_in">print</span>(url)</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(url=url, headers=headers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟浏览器向服务器发送请求</span></span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取响应的内容</span></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印数据</span></span><br><span class="line"><span class="built_in">print</span>(content)  <span class="comment"># 出现了安全验证, 应该是又被反爬了</span></span><br></pre></td></tr></table></figure>

<h4 id="2-5-2-get-请求的-urlencode-方法"><a href="#2-5-2-get-请求的-urlencode-方法" class="headerlink" title="2.5.2 get 请求的 urlencode 方法"></a>2.5.2 get 请求的 urlencode 方法</h4><blockquote>
<p>适用于多个参数的情况之下，直接定义为一个字典形式 </p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">base_url = <span class="string">&#x27;https://www.baidu.com/s?&#x27;</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;wd&#x27;</span>: <span class="string">&#x27;周杰伦&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sex&#x27;</span>: <span class="string">&#x27;男&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">new_data = urllib.parse.urlencode(data)</span><br><span class="line"><span class="built_in">print</span>(new_data)  <span class="comment"># wd=%E5%91%A8%E6%9D%B0%E4%BC%A6&amp;sex=%E7%94%B7</span></span><br><span class="line">url = base_url + new_data  <span class="comment"># 请求资源路径</span></span><br><span class="line"><span class="built_in">print</span>(url)</span><br></pre></td></tr></table></figure>

<h4 id="2-5-3-post-请求方式"><a href="#2-5-3-post-请求方式" class="headerlink" title="2.5.3 post 请求方式"></a>2.5.3 post 请求方式</h4><blockquote>
<p>注意：<strong>post请求的参数必须进行编码</strong>，编码之后必须调用 encode 方法  <code>data = urllib.parse.urlencode(data).encode(&#39;utf-8&#39;)</code></p>
<p>POST的请求<strong>参数是不会拼接在url后面的，而是需要放在请求对象定制的参数中</strong></p>
</blockquote>
<ul>
<li><p><strong>难点</strong>：找谁到底是你要的那个接口</p>
<blockquote>
<p>举例：百度翻译  <code>https://fanyi.baidu.com/sug</code></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695958780399.png" alt="1695958780399"></p>
</blockquote>
</li>
<li><p><strong>代码实例</strong>：</p>
<ul>
<li>案例1：百度翻译</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># post 请求百度翻译</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 请求地址</span></span><br><span class="line">url = <span class="string">&#x27;https://fanyi.baidu.com/sug&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 请求头</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 请求参数</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;kw&#x27;</span>: <span class="string">&#x27;spider&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># post 请求的参数, 必须要进行编码</span></span><br><span class="line">data = urllib.parse.urlencode(data).encode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(data)  <span class="comment"># kw=spider</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 定制请求对象 post 的请求参数是不会拼接在 url 后面的, 而是需要放在请求对象定制的参数中</span></span><br><span class="line">request = urllib.request.Request(url=url, data=data, headers=headers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 模拟浏览器向服务器发送请求</span></span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 获取响应的数据</span></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(content))  <span class="comment"># &lt;class &#x27;str&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(content)  <span class="comment"># &quot;data&quot;:[&#123;&quot;k&quot;:&quot;spider&quot;,&quot;v&quot;:&quot;n. \u8718\u86db; \u661f\u5f62\u8f6e\uff0c\u5341\u5b57\u53c9;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 7. 字符串变成 json 对象, 这回就显示中文了</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line">obj = json.loads(content)</span><br><span class="line"><span class="built_in">print</span>(obj)  <span class="comment"># &#x27;data&#x27;: [&#123;&#x27;k&#x27;: &#x27;spider&#x27;, &#x27;v&#x27;: &#x27;n. 蜘蛛; 星形轮，十字叉; 带柄三脚平底锅; 三脚架&#x27;&#125;,</span></span><br></pre></td></tr></table></figure>

<ul>
<li>案例2：百度详细翻译</li>
</ul>
<blockquote>
<p>利用 pytharm 快速加引号，但是 url 格式注意下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(.*?):(.*)</span><br><span class="line"><span class="string">&#x27;$1&#x27;</span>:<span class="string">&#x27;$2&#x27;</span>,</span><br></pre></td></tr></table></figure>

<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695964161361.png" alt="1695964161361"></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695964878773.png" alt="1695964878773"></p>
<p>遇到反爬，起决定性因素的是请求头中的 cookie，成功：</p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695964918990.png" alt="1695964918990"></p>
</blockquote>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695960152654.png" alt="1695960152654"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 百度翻译之详细翻译 注意反爬</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 请求地址</span></span><br><span class="line">url = <span class="string">&#x27;https://fanyi.baidu.com/v2transapi?from=en&amp;to=zh&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 请求头</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="comment"># &#x27;Accept&#x27;: &#x27;*/*&#x27;,</span></span><br><span class="line">    <span class="comment"># # &#x27;Accept-Encoding&#x27;: &#x27; gzip, deflate, br&#x27;,  # 注释掉这句！</span></span><br><span class="line">    <span class="comment"># &#x27;Accept-Language&#x27;: &#x27;zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Acs-Token&#x27;: &#x27;1695964467309_1695964468063_peDcqkvq6A8T3njv+K77v+KamobkMqSWfpCUJMKQYP/ChyN7W5OvAUIqMV/L2SbPjVfqcMkmR/Ns0/GUOysOeuMeG8t7YLflz8mpoHl1TFwSBWl3iAEg3+VU319melR/J9jHmt0EDdvCJn8EwNHDjWrd1Yis56PZXw2vUdC63L+f16WlARKCXxbTJrvQw5f1qssf+Z/itK3AReRKR+dAOnGWtvdbeU0DKt/HyfFwUKsnenFKcO0c0oMyRFi9/fnCXLy+HEaech+ZzZfB1oyInuQj9G9JJmbq2Qxx2WoOQYSQ4xiNlGNHgzJ8uGFwNLYNbJ6bxTGszkogMnHgYR1luX2o4CBhr+HddUEayDiT3CRsdNoXV4wFIQ13A8+JN1qHeSkpOz3+vGmEuSYnTObE+8CfSkkMUoMAvL/133QQDLpXDPsI1T0eEWNMBue+0EX6yahJB4MSd2iTKVXtlZtdkKHudQ0BfETC7EjMZh+MfIMSaHDV4vWeexbcc0rOI4PFWmwyoZIanp4rOr4LWg0y2d160OC2YNsG+WqsQa7YeHY=&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Cache-Control&#x27;: &#x27;no-cache&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Connection&#x27;: &#x27;keep-alive&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Content-Length&#x27;: &#x27;133&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded; charset=UTF-8&#x27;,</span></span><br><span class="line">    <span class="string">&#x27;Cookie&#x27;</span>: <span class="string">&#x27;BDUSS=E5yeFZUSFRyTUxzUEhVbXhzUkZOV3lyeDlGLUMyVWFranBDNlRiV21tTWlnRDVrSVFBQUFBJCQAAAAAAAAAAAEAAAB~ymGB06O7qGNhbzAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACLzFmQi8xZkT; BDUSS_BFESS=E5yeFZUSFRyTUxzUEhVbXhzUkZOV3lyeDlGLUMyVWFranBDNlRiV21tTWlnRDVrSVFBQUFBJCQAAAAAAAAAAAEAAAB~ymGB06O7qGNhbzAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACLzFmQi8xZkT; BIDUPSID=B26B49048A0C9099B1456DF64F0279FF; PSTM=1684546051; BAIDUID=C70948D5D545EED0115F390D9D6C8143:SL=0:NR=10:FG=1; BDORZ=B490B5EBF6F3CD402E515D22BCDA1598; BDRCVFR[feWj1Vr5u3D]=I67x6TjHwwYf0; delPer=0; PSINO=5; BAIDUID_BFESS=C70948D5D545EED0115F390D9D6C8143:SL=0:NR=10:FG=1; BA_HECTOR=ag01ag2g8k2hak81242k81001ihcet51p; ZFY=Y15oe:ADDl8fuenODkzShBnht8X9gotT2rS2ZtSq05IQ:C; H_PS_PSSID=39323_39353_39399_39396_39407_39097_39412_39436_39358_39308_39375_39233_39406_26350_39219_22158_39427; APPGUIDE_10_6_5=1; REALTIME_TRANS_SWITCH=1; FANYI_WORD_SWITCH=1; HISTORY_SWITCH=1; SOUND_SPD_SWITCH=1; SOUND_PREFER_SWITCH=1; Hm_lvt_64ecd82404c51e03dc91cb9e8c025574=1695958547; Hm_lpvt_64ecd82404c51e03dc91cb9e8c025574=1695964467; ab_sr=1.0.1_YTgxNjM4NjQ5Y2FjMmFjMjNmMjZhNDE1NjEwN2YxNmUyNTc0OGY1OGI3ZjMxOGFhMTJlNjBjMTM0NTc0YTI4OWVlNDIyZTUwZmIyNGYzZDdmYWIyZjQ3Y2Y2ZDc0YjVjMzcxM2MzMGVhNmE5OTZlYjA2ZjgyZTg4NTJhZThlYTJjZGE0MzBmYjRhZmUwMDBmYzU3NWU0YjY5YmFjYWQ1YmE1OGRkNzhiNGQ3Y2MwOWE4NTFlOTcxOTMxMjNlYzFl&#x27;</span>,</span><br><span class="line">    <span class="comment"># &#x27;Host&#x27;: &#x27;fanyi.baidu.com&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Origin&#x27;: &#x27;https://fanyi.baidu.com&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Pragma&#x27;: &#x27;no-cache&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Referer&#x27;: &#x27;https://fanyi.baidu.com/?aldtype=16047&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Sec-Ch-Ua&#x27;: &#x27;&quot;Chromium&quot;;v=&quot;116&quot;, &quot;Not)A;Brand&quot;;v=&quot;24&quot;, &quot;Microsoft Edge&quot;;v=&quot;116&quot;&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Sec-Ch-Ua-Mobile&#x27;: &#x27;?0&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Sec-Ch-Ua-Platform&#x27;: &#x27;&quot;Windows&quot;&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Sec-Fetch-Dest&#x27;: &#x27;empty&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Sec-Fetch-Mode&#x27;: &#x27;cors&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;Sec-Fetch-Site&#x27;: &#x27;same-origin&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;X-Requested-With&#x27;: &#x27;XMLHttpRequest&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 请求参数</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;from&#x27;</span>: <span class="string">&#x27;en&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;to&#x27;</span>: <span class="string">&#x27;zh&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;query&#x27;</span>: <span class="string">&#x27;math&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;transtype&#x27;</span>: <span class="string">&#x27;realtime&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;simple_means_flag&#x27;</span>: <span class="string">&#x27;3&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sign&#x27;</span>: <span class="string">&#x27;965097.678616&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;token&#x27;</span>: <span class="string">&#x27;e98f8f014d0905b8705c2da2366e9207&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;domain&#x27;</span>: <span class="string">&#x27;common&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;ts&#x27;</span>: <span class="string">&#x27;1695960046487&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 编码</span></span><br><span class="line">data = urllib.parse.urlencode(data).encode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 请求对象定制</span></span><br><span class="line">request = urllib.request.Request(url, data, headers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 模拟浏览器向服务器发送请求</span></span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 获取响应的数据</span></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(content)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">obj = json.loads(content)</span><br><span class="line"><span class="built_in">print</span>(obj)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-6-Ajax-请求"><a href="#2-6-Ajax-请求" class="headerlink" title="2.6 Ajax 请求"></a>2.6 Ajax 请求</h3><h4 id="2-6-1-get-请求"><a href="#2-6-1-get-请求" class="headerlink" title="2.6.1 get 请求"></a>2.6.1 get 请求</h4><p>案例：豆瓣电影：<a target="_blank" rel="noopener" href="https://movie.douban.com/typerank?type_name=%E5%8A%A8%E4%BD%9C&type=5&interval_id=100:90&action=">豆瓣电影分类排行榜 - 动作片 (douban.com)</a> </p>
<ul>
<li><strong>先抓接口</strong>，到底谁才是第一页的数据</li>
</ul>
<blockquote>
<p>第一页共 20 个电影，这个接口刚好返回了 0-19 的每个电影的详细信息</p>
</blockquote>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695965455172.png" alt="1695965455172"></p>
<ul>
<li><strong>查看标头</strong>，发现是get请求</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695965528954.png" alt="1695965528954"></p>
<ul>
<li><p><strong>代码编写</strong>：</p>
<ul>
<li>获取豆瓣电影第一页的数据</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get 请求</span></span><br><span class="line"><span class="comment"># 获取豆瓣电影第一页的数据, 并且保存起来</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://movie.douban.com/j/chart/top_list?type=5&amp;interval_id=100%3A90&amp;action=&amp;start=0&amp;limit=20&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求头</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 请求对象的定制</span></span><br><span class="line">request = urllib.request.Request(url=url, headers=headers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 获取响应数据</span></span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(content)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 下载数据到本地 文件相关知识</span></span><br><span class="line"><span class="comment"># open 方法默认使用 gbk 编码, 要想保存中文就需要指定编码为 utf-8</span></span><br><span class="line">fp = <span class="built_in">open</span>(<span class="string">&#x27;douban.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">fp.write(content)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 上面两句也可这么写</span></span><br><span class="line"><span class="comment"># with open(&#x27;douban1.json&#x27;, &#x27;w&#x27;, encoding=&#x27;utf-8&#x27;) as fp:</span></span><br><span class="line"><span class="comment">#     fp.write(content)</span></span><br></pre></td></tr></table></figure>

<ul>
<li>获取豆瓣电影前十页的数据</li>
</ul>
<blockquote>
<p>难点：接口的寻找：</p>
<p><code>https://movie.douban.com/j/chart/top_list?type=5&amp;interval_id=100%3A90&amp;action=&amp;start=0&amp;limit=20</code>  &#x3D;&#x3D;&gt; 第一页</p>
<p><code>https://movie.douban.com/j/chart/top_list?type=5&amp;interval_id=100%3A90&amp;action=&amp;start=20&amp;limit=20</code>  &#x3D;&#x3D;&gt; 第二页</p>
<p>找规律，可得：<code>start (page-1)*20</code></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://movie.douban.com/j/chart/top_list?type=5&amp;interval_id=100%3A90&amp;action=&amp;start=0&amp;limit=20</span></span><br><span class="line"><span class="comment"># https://movie.douban.com/j/chart/top_list?type=5&amp;interval_id=100%3A90&amp;action=&amp;start=20&amp;limit=20</span></span><br><span class="line"><span class="comment"># https://movie.douban.com/j/chart/top_list?type=5&amp;interval_id=100%3A90&amp;action=&amp;start=40&amp;limit=20</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># page    1   2   3   4</span></span><br><span class="line"><span class="comment"># start   0   20  40  60</span></span><br><span class="line"><span class="comment"># 规律：start (page-1)*20</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载豆瓣电影前10页的数据</span></span><br><span class="line"><span class="comment"># 1.请求对象的定制</span></span><br><span class="line"><span class="comment"># 2.获取响应的数据</span></span><br><span class="line"><span class="comment"># 3.下载数据到本地</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line"><span class="comment"># 封装函数实现</span></span><br><span class="line"><span class="comment"># 1. 请求对象的定制</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">creat_request</span>(<span class="params">page</span>):</span><br><span class="line">    <span class="comment"># 每页的 url 不同</span></span><br><span class="line">    base_url = <span class="string">&quot;https://movie.douban.com/j/chart/top_list?type=5&amp;interval_id=100%3A90&amp;action=&amp;&quot;</span></span><br><span class="line"></span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">&#x27;start&#x27;</span>: (page - <span class="number">1</span>) * <span class="number">20</span>,</span><br><span class="line">        <span class="string">&#x27;limit&#x27;</span>: <span class="number">20</span></span><br><span class="line">    &#125;</span><br><span class="line">    data = urllib.parse.urlencode(data)  <span class="comment"># get 请求后面就不用加 encode() 了</span></span><br><span class="line"></span><br><span class="line">    url = base_url + data</span><br><span class="line">    <span class="built_in">print</span>(url)</span><br><span class="line"></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    request = urllib.request.Request(url=url, headers=headers)</span><br><span class="line">    <span class="keyword">return</span> request</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.获取响应的数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_content</span>(<span class="params">request</span>):</span><br><span class="line">    response = urllib.request.urlopen(request)</span><br><span class="line">    content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> content</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.下载数据到本地</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">down_load</span>(<span class="params">page, content</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;douban_&#x27;</span> + <span class="built_in">str</span>(page) + <span class="string">&#x27;.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        fp.write(content)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 程序的入口</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    start_page = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入起始的页码: &#x27;</span>))</span><br><span class="line">    end_page = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入结束的页码: &#x27;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历</span></span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(start_page, end_page + <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 每一页都有自己的请求对象的定制</span></span><br><span class="line">        request = creat_request(page)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取响应数据</span></span><br><span class="line">        content = get_content(request)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 下载数据</span></span><br><span class="line">        down_load(page, content)</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="2-6-2-post-请求"><a href="#2-6-2-post-请求" class="headerlink" title="2.6.2 post 请求"></a>2.6.2 post 请求</h4><p>案例：KFC 官网：<a target="_blank" rel="noopener" href="http://www.kfc.com.cn/kfccda/storelist/index.aspx">肯德基餐厅信息查询 (kfc.com.cn)</a> </p>
<ul>
<li>找<strong>接口</strong><ul>
<li>请求地址: <code>http://www.kfc.com.cn/kfccda/ashx/GetStoreList.ashx?op=cname</code></li>
</ul>
</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695967907333.png" alt="1695967907333"></p>
<ul>
<li>找<strong>请求参数</strong></li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695969364799.png" alt="1695969364799"></p>
<ul>
<li><strong>代码实现</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一页</span></span><br><span class="line"><span class="comment"># 请求地址: http://www.kfc.com.cn/kfccda/ashx/GetStoreList.ashx?op=cname</span></span><br><span class="line"><span class="comment"># cname: 北京</span></span><br><span class="line"><span class="comment"># pid:</span></span><br><span class="line"><span class="comment"># pageIndex: 1</span></span><br><span class="line"><span class="comment"># pageSize: 10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二页</span></span><br><span class="line"><span class="comment"># 请求地址: http://www.kfc.com.cn/kfccda/ashx/GetStoreList.ashx?op=cname</span></span><br><span class="line"><span class="comment"># cname: 北京</span></span><br><span class="line"><span class="comment"># pid:</span></span><br><span class="line"><span class="comment"># pageIndex: 2</span></span><br><span class="line"><span class="comment"># pageSize: 10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实现前十页数据的获取</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 请求对象的定制</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">creat_request</span>(<span class="params">page</span>):</span><br><span class="line">    <span class="comment"># 每页的 url 不同</span></span><br><span class="line">    base_url = <span class="string">&#x27;http://www.kfc.com.cn/kfccda/ashx/GetStoreList.ashx?op=cname&#x27;</span></span><br><span class="line"></span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">&#x27;cname&#x27;</span>: <span class="string">&#x27;北京&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;pid&#x27;</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;pageIndex&#x27;</span>: page,</span><br><span class="line">        <span class="string">&#x27;pageSize&#x27;</span>: <span class="string">&#x27;10&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    data = urllib.parse.urlencode(data).encode(<span class="string">&#x27;utf-8&#x27;</span>)  <span class="comment"># 编码 encode</span></span><br><span class="line"></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    request = urllib.request.Request(url=base_url, headers=headers, data=data)</span><br><span class="line">    <span class="keyword">return</span> request</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.获取响应的数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_content</span>(<span class="params">request</span>):</span><br><span class="line">    response = urllib.request.urlopen(request)</span><br><span class="line">    content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> content</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.下载数据到本地</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">down_load</span>(<span class="params">page, content</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;kfc_&#x27;</span> + <span class="built_in">str</span>(page) + <span class="string">&#x27;.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        fp.write(content)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    start_page = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入起始的页码: &#x27;</span>))</span><br><span class="line">    end_page = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入结束的页码: &#x27;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 循环遍历</span></span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(start_page, end_page + <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 请求对象的定制</span></span><br><span class="line">        request = creat_request(page)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取网页数据</span></span><br><span class="line">        content = get_content(request)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 下载数据</span></span><br><span class="line">        down_load(page, content)</span><br></pre></td></tr></table></figure>

<h3 id="2-7-URLError-HTTPError"><a href="#2-7-URLError-HTTPError" class="headerlink" title="2.7 URLError\HTTPError"></a>2.7 URLError\HTTPError</h3><ul>
<li>HTTPError 类是 URLError 类的子类</li>
<li>导入的包 <code>urllib.error.HTTPError</code>，<code>urllib.error.URLError</code></li>
<li>通过 urllib 发送请求的时候又可能会发送失败，这时候若想让代码更加健壮，<strong>可以通过 try-except 进行异常捕获</strong></li>
<li><strong>代码示例</strong>：CSDN：<code>https://blog.csdn.net/qq_48108092/article/details/126097408</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://blog.csdn.net/qq_48108092/article/details/126097408</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.error</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://blog.csdn.net/qq_48108092/article/details/126097408&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    request = urllib.request.Request(url=url, headers=headers)</span><br><span class="line">    response = urllib.request.urlopen(request)</span><br><span class="line">    content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(content)</span><br><span class="line"><span class="keyword">except</span> urllib.error.HTTPError:  <span class="comment"># 假设写错url, 就会报这个错</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;系统正在升级...&#x27;</span>)</span><br><span class="line"><span class="keyword">except</span> urllib.error.URLError:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;我都说了, 系统正在升级...&#x27;</span>)  <span class="comment"># url 根本不存在?</span></span><br></pre></td></tr></table></figure>

<h3 id="2-8-cookie-登录"><a href="#2-8-cookie-登录" class="headerlink" title="2.8 cookie 登录"></a>2.8 cookie 登录</h3><blockquote>
<p>适用场景：数据采集的时候，需要绕过登录，然后进入到某个页面</p>
</blockquote>
<ul>
<li>个人信息页面是 utf-8, 但是还是报错编码错误, 因为没有进入到个人信息页面, 而是跳转到了登陆页面，那么登录页面不是 utf-8 所以报错</li>
<li>什么情况下访问不成功?<ul>
<li>因为请求头的信息不够, 所以不成功</li>
<li>&#x3D;&#x3D;如果有登录之后的 cookie, 那么我们就可以携带着 cookie 进入到登录后的任何页面&#x3D;&#x3D;</li>
<li>请求头中还有个参数 <code>&#39;referer&#39;: &#39;https://weibo.cn/&#39;</code> <ul>
<li>这个可以用于判断当前路径是不是由上一个路径进来的, 一般情况下是做<strong>图片的防盗链</strong>的</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="2-9-Handler-处理器"><a href="#2-9-Handler-处理器" class="headerlink" title="2.9 Handler 处理器"></a>2.9 Handler 处理器</h3><ul>
<li>不能定制请求头：<code>urllib.request.urlopen(url)</code></li>
<li>可以定制请求头：<code>urllib.request.Request(url,headers,data)</code></li>
<li><strong>定制更高级的请求头：Handler</strong><ul>
<li>动态 cookie 和 代理不能使用请求对象的定制</li>
</ul>
</li>
<li><strong>基本使用</strong>：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 需求: 使用 handler 访问百度, 获取网页源码</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://www.baidu.com&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(url=url, headers=headers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># handler build_opener open</span></span><br><span class="line"><span class="comment"># 1. 获取 handler 对象</span></span><br><span class="line">handler = urllib.request.HTTPHandler()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 通过 handler 获取 opener 对象</span></span><br><span class="line">opener = urllib.request.build_opener(handler)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 调用 open 方法</span></span><br><span class="line">response = opener.<span class="built_in">open</span>(request)</span><br><span class="line"></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(content)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2-10-代理服务器"><a href="#2-10-代理服务器" class="headerlink" title="2.10 代理服务器"></a>2.10 代理服务器</h3><ul>
<li>代理<strong>常用功能</strong>：<ul>
<li>突破自身ip访问限制，访问国外站点</li>
<li>访问一些单位或团体内部资源<ul>
<li>某大学FTP（前提是该代理地址在该资源的允许访问范围之内），使用教育网内地址免费代理服务器，就可以用于对教育网开房的各类FTP下载上传，以及各类资料查询共享等服务</li>
</ul>
</li>
<li>提高访问速度 <ul>
<li>扩展：通常代理服务器都设置一个较大的硬盘缓冲区，当有外界的信息通过时，同时也将其保存到缓冲区中，当其他用户再访问相同的信息时，则直接由缓冲区取出信息，传给用户，以提高访问速度</li>
</ul>
</li>
<li>隐藏真实ip</li>
</ul>
</li>
<li><strong>代码配置代理</strong>：</li>
</ul>
<blockquote>
<p>创建Reuqest对象</p>
<p>创建ProxyHandler对象</p>
<p>用handler对象创建opener对象</p>
<p>使用opener.open函数发送请求</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://www.baidu.com/s?wd=ip&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Cookie&#x27;</span>: <span class="string">&#x27;BDUSS=E5yeFZUSFRyTUxzUEhVbXhzUkZOV3lyeDlGLUMyVWFranBDNlRiV21tTWlnRDVrSVFBQUFBJCQAAAAAAAAAAAEAAAB~ymGB06O7qGNhbzAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACLzFmQi8xZkT; BDUSS_BFESS=E5yeFZUSFRyTUxzUEhVbXhzUkZOV3lyeDlGLUMyVWFranBDNlRiV21tTWlnRDVrSVFBQUFBJCQAAAAAAAAAAAEAAAB~ymGB06O7qGNhbzAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACLzFmQi8xZkT; BIDUPSID=B26B49048A0C9099B1456DF64F0279FF; PSTM=1684546051; BAIDUID=C70948D5D545EED0115F390D9D6C8143:SL=0:NR=10:FG=1; BD_UPN=12314753; BDORZ=B490B5EBF6F3CD402E515D22BCDA1598; BDRCVFR[feWj1Vr5u3D]=I67x6TjHwwYf0; delPer=0; BD_CK_SAM=1; PSINO=5; BAIDUID_BFESS=C70948D5D545EED0115F390D9D6C8143:SL=0:NR=10:FG=1; BA_HECTOR=ag01ag2g8k2hak81242k81001ihcet51p; ZFY=Y15oe:ADDl8fuenODkzShBnht8X9gotT2rS2ZtSq05IQ:C; B64_BOT=1; sug=3; sugstore=0; ORIGIN=2; bdime=21111; ab_sr=1.0.1_MWIwMmYyMmFmM2YxN2QyZGJjMTQ4YTRlNDU5NDBhY2YzNDY0OGIyNDFjZDcyOGIxNjBlNzZlZTIwYWUxMTk3MjBkNTMxMDhjOTU3ZmRmOWNlZDA3MjEwMjg1MzZlMzZkMmEyNWIzMjUxNWVlODE1YjRhOTAyYzllZTgzZDk0Yzc1MDg0YWE5ZTRlOWJkYzk1Yjg5N2M4ZTk3NDRjNWQ3MmNlOGI1ZGIyNGMxMzkzZDY4ZWQyNTA1MWIxZjZkOGEy; RT=&quot;z=1&amp;dm=baidu.com&amp;si=bee5a4dd-dfb0-43a8-8226-878c0904dd53&amp;ss=ln47d4cw&amp;sl=0&amp;tt=0&amp;bcn=https%3A%2F%2Ffclog.baidu.com%2Flog%2Fweirwood%3Ftype%3Dperf&amp;ul=1xd&amp;hd=1xx&quot;; H_PS_PSSID=39323_39353_39399_39396_39407_39097_39412_39436_39358_39308_39375_39233_39406_26350_39219_22158_39427; COOKIE_SESSION=0_0_0_0_1_0_1_0_0_0_0_0_0_0_3_0_1695967725_0_1695967722%7C1%230_0_1695967722%7C1&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求对象定制</span></span><br><span class="line">request = urllib.request.Request(url=url, headers=headers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟浏览器访问服务器</span></span><br><span class="line"><span class="comment"># response=urllib.request.urlopen(request)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用代理 ip 进行访问, 以字典形式存在</span></span><br><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;221.4.241.198:9091&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># handler build_opener open</span></span><br><span class="line">handler = urllib.request.ProxyHandler(proxies=proxies)</span><br><span class="line">opener = urllib.request.build_opener(handler)</span><br><span class="line">response = opener.<span class="built_in">open</span>(request)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获得响应信息</span></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存本地</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;proxy.html&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(content)</span><br></pre></td></tr></table></figure>

<h1 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h1><blockquote>
<p>之前在urlib的学习中，我们能将网页的网页源码爬取下来。但是我们我们仅仅需要其中的部分数据，此时就需要引入新的概念——解析。</p>
<p>目前使用最多的解析方法包括xpath、JsonPath、BeautifulSoup等。</p>
<p>参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_60146935/article/details/132137743">Python爬虫的解析（学习于b站尚硅谷）_知乎云烟的博客-CSDN博客</a>  </p>
</blockquote>
<h2 id="1-xpath"><a href="#1-xpath" class="headerlink" title="1. xpath"></a>1. xpath</h2><h3 id="1-1-xpath-插件安装"><a href="#1-1-xpath-插件安装" class="headerlink" title="1.1 xpath 插件安装"></a>1.1 xpath 插件安装</h3><ul>
<li><p>如果是在 <strong>google 浏览器上</strong></p>
<ul>
<li>就直接将网盘里的 xpath.zip 拖到扩展程序里面</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695974655310.png" alt="1695974655310"></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695974736550.png" alt="1695974736550"></p>
<ul>
<li>然后打开任意一个网页，按住快捷键 <code>ctrl+shift+x</code> 即可出现调试工具</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695974754513.png" alt="1695974754513"></p>
</li>
<li><p>如果是在 <strong>edge 浏览器上</strong>，参考教程：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_59153970/article/details/125252748">在Edge中使用Xpath——更改快捷键_edge xpath_鹤行川.的博客-CSDN博客</a> </p>
<ul>
<li><p>由于Xpath的快捷键 <code>Ctrl+Shift+X</code> 已经被一个叫做Web选择的功能占用（这个功能可以复制不让复制的页面内容！！震惊，才知道！），所以先下载下来修改快捷键后的 xpath 版本</p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695975202488.png" alt="1695975202488"></p>
</li>
<li><p>然后打开 edge 的扩展功能，同时开启<strong>开发人员模式</strong>，解压后拖入即可，使用快捷键 <code>ctrl+alt+X</code> 即可打开调试窗口，注意插件的文件不要乱移位置</p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695975389083.png" alt="1695975389083"></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695985804035.png" alt="1695985804035"></p>
</li>
</ul>
</li>
</ul>
<h3 id="1-2-xpath-基本使用"><a href="#1-2-xpath-基本使用" class="headerlink" title="1.2 xpath 基本使用"></a>1.2 xpath 基本使用</h3><h4 id="1-2-1-lxml-库的安装"><a href="#1-2-1-lxml-库的安装" class="headerlink" title="1.2.1 lxml 库的安装"></a>1.2.1 lxml 库的安装</h4><ul>
<li><p>还需要安装一个库 <code>lxml</code> 才能用：</p>
<p><code>pip install lxml -i https://pypi.douban.com/simple</code></p>
</li>
<li><p>这个库的<strong>安装路径需要在你目前项目所用的 python 解释器的目录下边</strong></p>
</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695975654857.png" alt="1695975654857"></p>
<ul>
<li>输入命令进行安装</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd Scripts</span><br><span class="line">pip install lxml</span><br></pre></td></tr></table></figure>

<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695975901027.png" alt="1695975901027"></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695976053768.png" alt="1695976053768"></p>
<ul>
<li>导入验证：<code>from lxml import etree</code></li>
</ul>
<h4 id="1-2-2-xpath-解析"><a href="#1-2-2-xpath-解析" class="headerlink" title="1.2.2 xpath 解析"></a>1.2.2 xpath 解析</h4><ul>
<li><strong>解析什么</strong>？<ul>
<li>本地文件<ul>
<li><code>etree.parse(&#39;XX.html&#39;) </code></li>
</ul>
</li>
<li><strong>服务器响应的数据</strong><ul>
<li><code>etree.HTML(response.read().decode(&#39;utf‐8&#39;)</code></li>
<li>实际这种情况用的多</li>
</ul>
</li>
</ul>
</li>
<li>xpath <strong>基本语法</strong>：</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695976852724.png" alt="1695976852724"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="comment"># xpath 解析</span></span><br><span class="line"><span class="comment"># 1. 本地文件  etree.parse(&#x27;XX.html&#x27;)</span></span><br><span class="line"><span class="comment"># 2. 服务器响应的数据 etree.HTML(response.read().decode(&#x27;utf‐8&#x27;) 实际这种情况用的多</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. xpath 解析本地文件</span></span><br><span class="line">tree = etree.parse(<span class="string">&#x27;01_xpath.html&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 补充: xpath 语法</span></span><br><span class="line"><span class="comment"># (1) tree.xpath(&#x27;xpath路径&#x27;)  `//`代表子孙, `/`代表孙子</span></span><br><span class="line"><span class="comment"># eg1. 查找 ul 下面的 li</span></span><br><span class="line">li_list = tree.xpath(<span class="string">&#x27;//body/ul/li&#x27;</span>)  <span class="comment"># 此处也可以写 //body//li</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(li_list))  <span class="comment"># 判断列表的长度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (2) 谓词查询 `//div[@id]`  `//div[@id=&quot;maincontent&quot;]`</span></span><br><span class="line"><span class="comment"># eg2.1 查找所有有 id 属性的 li 标签</span></span><br><span class="line"><span class="comment"># test() 可用于获取标签中的内容</span></span><br><span class="line">li_list = tree.xpath(<span class="string">&#x27;//ul/li[@id]/text()&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(li_list)  <span class="comment"># [&#x27;北京&#x27;, &#x27;上海&#x27;]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(li_list))  <span class="comment"># 2</span></span><br><span class="line"><span class="comment"># eg2.2 查找id为l1的li标签, 注意引号的问题</span></span><br><span class="line">li_list = tree.xpath(<span class="string">&#x27;//ul/li[@id=&quot;l1&quot;]/text()&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(li_list)  <span class="comment"># [&#x27;北京&#x27;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (3) 属性查询</span></span><br><span class="line"><span class="comment"># eg3. 查找id为l1的li标签的class的属性值</span></span><br><span class="line">li = tree.xpath(<span class="string">&#x27;//ul/li[@id=&quot;l1&quot;]/@class&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># (4) 模糊查询（用的不多）</span></span><br><span class="line"><span class="comment"># eg4.1 查询id中包含l的li标签</span></span><br><span class="line">li_list = tree.xpath(<span class="string">&#x27;//ul/li[contains(@id, &quot;l&quot;)]/text()&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(li_list)  <span class="comment"># [&#x27;北京&#x27;, &#x27;上海&#x27;]</span></span><br><span class="line"><span class="comment"># eg4.2 查询id的值以c开头的li标签</span></span><br><span class="line">li_list = tree.xpath(<span class="string">&#x27;//ul/li[starts-with(@id, &quot;c&quot;)]/text()&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="1-3-获取百度页面的-百度一下-四个字"><a href="#1-3-获取百度页面的-百度一下-四个字" class="headerlink" title="1.3 获取百度页面的 百度一下 四个字"></a>1.3 获取百度页面的 百度一下 四个字</h3><ul>
<li>先获取页面的源码，找到 <code>百度一下</code> 四个字的所在位置</li>
</ul>
<p><code>&lt;span class=&quot;s_btn_wr&quot;&gt;&lt;input type=&quot;submit&quot; id=&quot;su&quot; value=&quot;百度一下&quot; class=&quot;bg s_btn&quot;&gt;</code></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695978716209.png" alt="1695978716209"></p>
<ul>
<li>用xpath插件进行调试，可以找到合适的获得我们想要的数据的路径</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695979216574.png" alt="1695979216574"></p>
<ul>
<li><strong>代码实现</strong>：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 获取网页的源码</span></span><br><span class="line"><span class="comment"># 2. 解析  解析的是服务器响应的文件, 用 etree.HTML()</span></span><br><span class="line"><span class="comment"># 3. 打印</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 获取网页源码</span></span><br><span class="line">url = <span class="string">&#x27;https://www.baidu.com/&#x27;</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Cookie&#x27;</span>: <span class="string">&#x27;BDUSS=E5yeFZUSFRyTUxzUEhVbXhzUkZOV3lyeDlGLUMyVWFranBDNlRiV21tTWlnRDVrSVFBQUFBJCQAAAAAAAAAAAEAAAB~ymGB06O7qGNhbzAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACLzFmQi8xZkT; BDUSS_BFESS=E5yeFZUSFRyTUxzUEhVbXhzUkZOV3lyeDlGLUMyVWFranBDNlRiV21tTWlnRDVrSVFBQUFBJCQAAAAAAAAAAAEAAAB~ymGB06O7qGNhbzAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACLzFmQi8xZkT; BIDUPSID=B26B49048A0C9099B1456DF64F0279FF; PSTM=1684546051; BAIDUID=C70948D5D545EED0115F390D9D6C8143:SL=0:NR=10:FG=1; BD_UPN=12314753; BDORZ=B490B5EBF6F3CD402E515D22BCDA1598; BDRCVFR[feWj1Vr5u3D]=I67x6TjHwwYf0; delPer=0; BD_CK_SAM=1; PSINO=5; BAIDUID_BFESS=C70948D5D545EED0115F390D9D6C8143:SL=0:NR=10:FG=1; BA_HECTOR=ag01ag2g8k2hak81242k81001ihcet51p; B64_BOT=1; sug=3; sugstore=0; ORIGIN=2; bdime=21111; RT=&quot;z=1&amp;dm=baidu.com&amp;si=bee5a4dd-dfb0-43a8-8226-878c0904dd53&amp;ss=ln47d4cw&amp;sl=0&amp;tt=0&amp;bcn=https%3A%2F%2Ffclog.baidu.com%2Flog%2Fweirwood%3Ftype%3Dperf&amp;ul=1xd&amp;hd=1xx&quot;; COOKIE_SESSION=0_0_0_0_1_0_1_0_0_0_0_0_0_0_3_0_1695967725_0_1695967722%7C1%230_0_1695967722%7C1; ZFY=jKLYva:AwW:AlQpwrTh6Gt4SREDbR7NGeps2ei6L3zLXg:C; H_PS_PSSID=39323_39353_39399_39396_39407_39097_39412_39436_39358_39308_39375_39233_39406_26350_39219_22158_39427; baikeVisitId=50aa753e-979e-40e9-b6dc-b1730a994990; ab_sr=1.0.1_MDJlMTU2MDk2ZWFlYTMyNmQ2Njc5OWJjYzIwOGJjZDE2MjUwOWQyOTMxMDc5N2I2ZmJhZjczMjkyZjg5YzQ0MjAxYzUyZGEwZDU5MGY5NmZmNmMzZDgwNDkwOGQ5YTBmNTg2MGQ5ZjE0ZWVkNmUxMjUzZGY3NDU4MzZhYTU3NjMzYmVmOTg1NzZkNTQ4OTJkZjlhNThkZjAxNzExMTBjOTAxODlmODI3Nzg3ZGQwNGVkMzc1M2JkOWI5NTNlNmQ2&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 1.1 请求对象的定制</span></span><br><span class="line">request = urllib.request.Request(url=url, headers=headers)</span><br><span class="line"><span class="comment"># 1.2 模拟浏览器访问服务器</span></span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"><span class="comment"># 1.3 获取网页源码</span></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="comment"># print(content)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 解析网页源码, 获取我们想要的数据</span></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.1 解析服务器响应的文件</span></span><br><span class="line">tree = etree.HTML(content)</span><br><span class="line"><span class="comment"># 2.2 获取想要的数据 用那个xpath插件调试寻找正确的路径 xpath的返回值是一个列表类型的数据, 所以加上[0], 即可得到纯正的四个大字</span></span><br><span class="line">result = tree.xpath(<span class="string">&#x27;//input[@id=&quot;su&quot;]/@value&#x27;</span>)[<span class="number">0</span>]  <span class="comment"># 百度一下</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>

<h3 id="1-4-站长素材-含懒加载、如何下载其中的高清图"><a href="#1-4-站长素材-含懒加载、如何下载其中的高清图" class="headerlink" title="1.4 站长素材(含懒加载、如何下载其中的高清图)"></a>1.4 站长素材(含懒加载、如何下载其中的高清图)</h3><ul>
<li><p>网址：<code>https://sc.chinaz.com/</code></p>
</li>
<li><p>xpath 调试获取图片的地址和alt值，但是这里好像返回的和页面中的不太一样，最后输出的结果为空，还是直接打印出 content 之后用 ctrl+F 查找吧</p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695984242783.png" alt="1695984242783"></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695984267881.png" alt="1695984267881"></p>
</li>
</ul>
<p><code>//div[@class=&#39;item masonry-brick&#39;]/img/@data-original</code></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695983936153.png" alt="1695983936153"></p>
<p><code>//div[@class=&#39;item masonry-brick&#39;]/img/@alt</code></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695983993986.png" alt="1695983993986"></p>
<ul>
<li><strong>代码实现</strong>：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 请求对象的定制</span></span><br><span class="line"><span class="comment"># 2. 获取网页源码</span></span><br><span class="line"><span class="comment"># 3. 下载</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 需求: 下载前十页的图片</span></span><br><span class="line"><span class="comment"># 第一页的地址</span></span><br><span class="line"><span class="comment"># https://sc.chinaz.com/tupian/taikongkexuetupian.html</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二页的地址</span></span><br><span class="line"><span class="comment"># https://sc.chinaz.com/tupian/taikongkexuetupian_2.html</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 分析: 除了第一页和其他页不一样, 其他页的末尾都是 _page</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 请求对象的定制</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">creat_request</span>(<span class="params">page</span>):</span><br><span class="line">    <span class="keyword">if</span> page == <span class="number">1</span>:</span><br><span class="line">        url = <span class="string">&#x27;https://sc.chinaz.com/tupian/taikongkexuetupian.html&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 每页的 url 不同</span></span><br><span class="line">        url = <span class="string">&#x27;https://sc.chinaz.com/tupian/taikongkexuetupian_&#x27;</span> + <span class="built_in">str</span>(page) + <span class="string">&#x27;.html&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(url)</span><br><span class="line"></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    request = urllib.request.Request(url=url, headers=headers)</span><br><span class="line">    <span class="keyword">return</span> request</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.获取网页的源码</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_content</span>(<span class="params">request</span>):</span><br><span class="line">    response = urllib.request.urlopen(request)</span><br><span class="line">    content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="comment"># print(content)</span></span><br><span class="line">    <span class="keyword">return</span> content</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.下载数据到本地</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">down_load</span>(<span class="params">content</span>):</span><br><span class="line">    <span class="comment"># 下载图片, 需要图片地址(在网页源码中获取)和文件的名字(在 alt 中获取)</span></span><br><span class="line">    <span class="comment"># 那么就需要用到 xpath 进行解析</span></span><br><span class="line">    tree = etree.HTML(content)</span><br><span class="line">    <span class="comment"># 获取 alt 属性</span></span><br><span class="line">    name_list = tree.xpath(<span class="string">&#x27;//div[@class=&quot;item&quot;]/img/@alt&#x27;</span>)</span><br><span class="line">    <span class="comment"># 获取图片地址, 此处注意有的设计图片的网站会进行懒加载, 原先属性名可能是src2,需要等待你滑倒那个位置才会变成src,所以要用src2去获取</span></span><br><span class="line">    src_list = tree.xpath(<span class="string">&#x27;//div[@class=&quot;item&quot;]/img/@data-original&#x27;</span>)</span><br><span class="line">    <span class="comment"># print(len(src_list))  # 40</span></span><br><span class="line">    <span class="comment"># print(len(name_list))  # 40</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历下载每一张图片</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(name_list)):</span><br><span class="line">        name = name_list[i]</span><br><span class="line">        src = src_list[i]</span><br><span class="line">        <span class="comment"># print(name, src)  # 冬日唯美星空图片 //scpic2.chinaz.net/files/default/imgs/2023-03-01/0b5c5cf3cc6bb41d_s.jpg</span></span><br><span class="line">        <span class="comment"># 注意返回的地址前面省略了 https: 需要补上才可以下载</span></span><br><span class="line">        url = <span class="string">&#x27;https:&#x27;</span> + src</span><br><span class="line">        <span class="built_in">print</span>(name, url)</span><br><span class="line"></span><br><span class="line">        urllib.request.urlretrieve(url, filename=<span class="string">&#x27;./img/&#x27;</span> + name + <span class="string">&#x27;.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    start_page = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入起始的页码: &#x27;</span>))</span><br><span class="line">    end_page = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入结束的页码: &#x27;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历</span></span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(start_page, end_page + <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 1. 请求对象的定制</span></span><br><span class="line">        request = creat_request(page)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2. 获取网页的源码</span></span><br><span class="line">        content = get_content(request)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 下载数据</span></span><br><span class="line">        down_load(content)</span><br></pre></td></tr></table></figure>

<h2 id="2-JsonPath"><a href="#2-JsonPath" class="headerlink" title="2. JsonPath"></a>2. JsonPath</h2><blockquote>
<p>JsonPath 适用于<strong>解析网页源码的返回值为Json数据的网站</strong></p>
<p>比如打开“淘票票”：<code>https://dianying.taobao.com/</code>，按F12 打开检查，点到网络。然后点击“淘票票”中的城市，会得到一个网络包，发现它是一个Json数据。后面我们将爬取该数据包存储的淘票票支持的城市 </p>
</blockquote>
<h3 id="2-1-基本介绍"><a href="#2-1-基本介绍" class="headerlink" title="2.1 基本介绍"></a>2.1 基本介绍</h3><h4 id="2-1-1-安装及使用"><a href="#2-1-1-安装及使用" class="headerlink" title="2.1.1 安装及使用"></a>2.1.1 安装及使用</h4><blockquote>
<p>jsonpath <strong>只能解析本地文件，不能解析服务器响应的文件</strong></p>
</blockquote>
<ul>
<li>pip 安装：<code>pip install jsonpath</code></li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695985926957.png" alt="1695985926957"></p>
<ul>
<li>jsonpath 的使用：<ul>
<li>导入 <code>import jsonpath</code></li>
<li><code>obj = json.load(open(&#39;json文件&#39;, &#39;r&#39;, encoding=&#39;utf-8&#39;))</code></li>
<li><code>ret = jsonpath.jsonpath(obj, &#39;jsonpath语法&#39;)</code></li>
</ul>
</li>
</ul>
<h4 id="2-1-2-基本语法-与-xpath-对比"><a href="#2-1-2-基本语法-与-xpath-对比" class="headerlink" title="2.1.2 基本语法(与 xpath 对比)"></a>2.1.2 基本语法(与 xpath 对比)</h4><blockquote>
<p>参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/luxideyao/article/details/77802389">JSONPath-简单入门-CSDN博客</a> </p>
</blockquote>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695985322714.png" alt="1695985322714"></p>
<h4 id="2-1-3-基本使用"><a href="#2-1-3-基本使用" class="headerlink" title="2.1.3 基本使用"></a>2.1.3 基本使用</h4><ul>
<li>已知有如下的json文件</li>
</ul>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;store&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;book&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span> <span class="attr">&quot;category&quot;</span><span class="punctuation">:</span> <span class="string">&quot;reference&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;author&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Nigel Rees&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Sayings of the Century&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;price&quot;</span><span class="punctuation">:</span> <span class="number">8.95</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span> <span class="attr">&quot;category&quot;</span><span class="punctuation">:</span> <span class="string">&quot;fiction&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;author&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Evelyn Waugh&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Sword of Honour&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;price&quot;</span><span class="punctuation">:</span> <span class="number">12.99</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span> <span class="attr">&quot;category&quot;</span><span class="punctuation">:</span> <span class="string">&quot;fiction&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;author&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Herman Melville&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Moby Dick&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;isbn&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0-553-21311-3&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;price&quot;</span><span class="punctuation">:</span> <span class="number">8.99</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span> <span class="attr">&quot;category&quot;</span><span class="punctuation">:</span> <span class="string">&quot;fiction&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;author&quot;</span><span class="punctuation">:</span> <span class="string">&quot;J. R. R. Tolkien&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span> <span class="string">&quot;The Lord of the Rings&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;isbn&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0-395-19395-8&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;price&quot;</span><span class="punctuation">:</span> <span class="number">22.99</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;bicycle&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;color&quot;</span><span class="punctuation">:</span> <span class="string">&quot;red&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;price&quot;</span><span class="punctuation">:</span> <span class="number">19.95</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>用jsonpath代码实现爬取数据：</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695986122236.png" alt="1695986122236"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> jsonpath</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取本地的 json 文件</span></span><br><span class="line">obj = json.load(<span class="built_in">open</span>(<span class="string">&#x27;04_jsonpath_store.json&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(obj)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 爬取书店所有书的作者, 如果只要特定的第几本书, 可以这样写, 如第一本书: &#x27;$.store.book[0].author&#x27;</span></span><br><span class="line">author_list = jsonpath.jsonpath(obj, <span class="string">&#x27;$.store.book[*].author&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(author_list)  <span class="comment"># [&#x27;Nigel Rees&#x27;, &#x27;Evelyn Waugh&#x27;, &#x27;Herman Melville&#x27;, &#x27;J. R. R. Tolkien&#x27;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 所有的作者</span></span><br><span class="line">author_list = jsonpath.jsonpath(obj, <span class="string">&#x27;$..author&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(author_list)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. store 下面的所有的元素</span></span><br><span class="line">tag_list = jsonpath.jsonpath(obj, <span class="string">&#x27;$.store.*&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(tag_list)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. store 里面所有东西的 price</span></span><br><span class="line">price_list = jsonpath.jsonpath(obj, <span class="string">&#x27;$.store..price&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(price_list)  <span class="comment"># [8.95, 12.99, 8.99, 22.99, 19.95]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 第三个书</span></span><br><span class="line">book = jsonpath.jsonpath(obj, <span class="string">&#x27;$..book[2]&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(book)</span><br><span class="line"><span class="comment"># [&#123;&#x27;category&#x27;: &#x27;fiction&#x27;, &#x27;author&#x27;: &#x27;Herman Melville&#x27;, &#x27;title&#x27;: &#x27;Moby Dick&#x27;, &#x27;isbn&#x27;: &#x27;0-553-21311-3&#x27;, &#x27;price&#x27;: 8.99&#125;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 最后一本书</span></span><br><span class="line">book = jsonpath.jsonpath(obj, <span class="string">&#x27;$..book[(@.length-1)]&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(book)</span><br><span class="line"><span class="comment"># [&#123;&#x27;category&#x27;: &#x27;fiction&#x27;, &#x27;author&#x27;: &#x27;J. R. R. Tolkien&#x27;, &#x27;title&#x27;: &#x27;The Lord of the Rings&#x27;, &#x27;isbn&#x27;: &#x27;0-395-19395-8&#x27;, &#x27;price&#x27;: 22.99&#125;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 7. 前两本书</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;-------&#x27;</span>)</span><br><span class="line"><span class="comment"># 注意这里[0,1]之间不可以有空格</span></span><br><span class="line">book_list = jsonpath.jsonpath(obj, <span class="string">&#x27;$..book[0,1]&#x27;</span>)</span><br><span class="line"><span class="comment"># 或者 book_list = jsonpath.jsonpath(obj, &#x27;$..book[:2]&#x27;)</span></span><br><span class="line"><span class="built_in">print</span>(book_list)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 8. 过滤出所有包含版本号 isbn 的书（条件过滤, 需要加个问号）</span></span><br><span class="line">book_list = jsonpath.jsonpath(obj, <span class="string">&#x27;$..book[?(@.isbn)]&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(book_list)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 9. 哪本书超过了10块钱</span></span><br><span class="line">book_list = jsonpath.jsonpath(obj, <span class="string">&#x27;$..book[?(@.price&gt;10)]&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(book_list)</span><br></pre></td></tr></table></figure>

<h3 id="2-2-JsonPath-解析淘票票"><a href="#2-2-JsonPath-解析淘票票" class="headerlink" title="2.2 JsonPath 解析淘票票"></a>2.2 JsonPath 解析淘票票</h3><ul>
<li><p>网址：<code>https://dianying.taobao.com/ </code></p>
</li>
<li><p>需求：获取所有的能买票的城市信息</p>
<ul>
<li><p>找接口，看下会不会有些反爬，请求地址：</p>
<p><code>https://dianying.taobao.com/cityAction.json?activityId&amp;_ksTS=1695987569488_108&amp;jsoncallback=jsonp109&amp;action=cityAction&amp;n_s=new&amp;event_submit_doGetAllRegion=true</code></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695987733171.png" alt="1695987733171"></p>
</li>
<li><p>访问一下，发现没给我们数据，应该是做了限制，不仅仅只校验UA，待会在请求头里我们还要给它点东西</p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695987705920.png" alt="1695987705920"></p>
</li>
<li><p>复制所有请求头，尝试下</p>
</li>
</ul>
</li>
<li><p>代码实现</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://dianying.taobao.com/cityAction.json?activityId&amp;_ksTS=1695987569488_108&amp;jsoncallback=jsonp109&amp;action=cityAction&amp;n_s=new&amp;event_submit_doGetAllRegion=true&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;text/javascript, application/javascript, application/ecmascript, application/x-ecmascript, */*; q=0.01&#x27;</span>,</span><br><span class="line">    <span class="comment"># &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate, br&#x27;,</span></span><br><span class="line">    <span class="string">&#x27;Accept-Language&#x27;</span>: <span class="string">&#x27;zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Bx-V&#x27;</span>: <span class="string">&#x27;2.5.3&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Cache-Control&#x27;</span>: <span class="string">&#x27;no-cache&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Cookie&#x27;</span>: <span class="string">&#x27;t=7cec2d4496f4b4f1e67f2b3781af9f07; cookie2=1a7dff465bd9981f135e2c3fa2c17538; v=0; _tb_token_=e17995433ee3e; cna=IJqeHFQN328BASQOBHM61WKq; xlly_s=1; tfstk=d499nsXEs20geUMNDShngOneRDnntdKZjF-7nZbgGeLpzFnNi5AMMrQpVc7igf8v9ETFsN9v0-IXcEoNoclHbhWVh40kkYxwbMatr4VCK8uh3tgorW2f_YB2ySUCsTrU--aUYRvMHGG4F89vkS6fX1QYnwex8mjO6dx1J4g5Qo9keZM_raI01DnLgS51YN4Rrb1..; l=fBIl_TtePNX1FeifBOfwnurza77OhIRAguPzaNbMi9fP_JCH5QTlW1HPceLMCnGVFsewR3rNfwdWBeYBqC2sjqj4axom45HmnmOk-Wf..; isg=BGBg3JJQEbUhTK2xJ5kiT7IFMW4yaUQz8Y4DhdpxQnsO1QD_gnjDw3rrbX3V5fwL&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Pragma&#x27;</span>: <span class="string">&#x27;no-cache&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Referer&#x27;</span>: <span class="string">&#x27;https://dianying.taobao.com/&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Sec-Ch-Ua&#x27;</span>: <span class="string">&#x27;&quot;Chromium&quot;;v=&quot;116&quot;, &quot;Not)A;Brand&quot;;v=&quot;24&quot;, &quot;Microsoft Edge&quot;;v=&quot;116&quot;&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Sec-Ch-Ua-Mobile&#x27;</span>: <span class="string">&#x27;?0&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Sec-Ch-Ua-Platform&#x27;</span>: <span class="string">&#x27;&quot;Windows&quot;&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Sec-Fetch-Dest&#x27;</span>: <span class="string">&#x27;empty&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Sec-Fetch-Mode&#x27;</span>: <span class="string">&#x27;cors&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Sec-Fetch-Site&#x27;</span>: <span class="string">&#x27;same-origin&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;X-Requested-With&#x27;</span>: <span class="string">&#x27;XMLHttpRequest&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(url=url, headers=headers)</span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(content)  <span class="comment"># 获取到的 json 文件前面有 jsonp109(&#123;&quot;returnCode&quot;:&quot;0&quot;,&quot;ret...</span></span><br><span class="line"><span class="comment"># 也就是 jsonp, jsonp 是跨域的一种解决方案, 但是我们不要前面的这个以及末尾对应的圆括号</span></span><br><span class="line"><span class="comment"># 利用 split 对获取到的 json 串进行开头和末尾的切割</span></span><br><span class="line">content = content.split(<span class="string">&#x27;(&#x27;</span>)[<span class="number">1</span>].split(<span class="string">&#x27;)&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;05_jsonpath_ticket.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(content)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> jsonpath</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将前面下载下来的json数据的本地打开文件, 然后再用jsonpath进行筛选想要的数据</span></span><br><span class="line">obj = json.load(<span class="built_in">open</span>(<span class="string">&#x27;05_jsonpath_ticket.json&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line"></span><br><span class="line">city_list = jsonpath.jsonpath(obj, <span class="string">&#x27;$..regionName&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(city_list)  <span class="comment"># 成功获取所有的城市</span></span><br></pre></td></tr></table></figure>

<ul>
<li>成功获取到数据</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695988630074.png" alt="1695988630074"></p>
<ul>
<li>然后用 jsonpath 对保存到本地的json文件进行解析，筛选我们想要的所有的城市列表：</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695988930026.png" alt="1695988930026"></p>
<h2 id="3-BeautifulSoup-即bs4"><a href="#3-BeautifulSoup-即bs4" class="headerlink" title="3. BeautifulSoup(即bs4)"></a>3. BeautifulSoup(即bs4)</h2><blockquote>
<p>和 xpath 是同一重量级的技术</p>
</blockquote>
<h3 id="3-1-基本使用"><a href="#3-1-基本使用" class="headerlink" title="3.1 基本使用"></a>3.1 基本使用</h3><h4 id="3-1-1-简介"><a href="#3-1-1-简介" class="headerlink" title="3.1.1 简介"></a>3.1.1 简介</h4><ul>
<li><p>和 lxml 一样，是一个 html 的解析器，主要功能也是解析和提取数据</p>
</li>
<li><p>优缺</p>
<ul>
<li>缺点：效率没有 lxml 高</li>
</ul>
<blockquote>
<p>这缺点感觉有点不太可</p>
</blockquote>
<ul>
<li>优点：接口设计人性化，使用方便</li>
</ul>
</li>
</ul>
<h4 id="3-1-2-安装及创建"><a href="#3-1-2-安装及创建" class="headerlink" title="3.1.2 安装及创建"></a>3.1.2 安装及创建</h4><ul>
<li>安装：<code>pip install bs4</code></li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695989570174.png" alt="1695989570174"></p>
<ul>
<li>导入：<code>from bs4 import BeautifulSoup</code></li>
<li>创建对象：<ul>
<li>服务器响应的文件生成对象：<code>soup = BeautifulSoup(response.read().decode(), &#39;lxml&#39;)</code></li>
<li>本地文件生成对象：<code>soup = BeautifulSoup(open(&#39;1.html&#39;), &#39;lxml&#39;)</code></li>
</ul>
</li>
</ul>
<h4 id="3-1-3-节点定位"><a href="#3-1-3-节点定位" class="headerlink" title="3.1.3 节点定位"></a>3.1.3 节点定位</h4><p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695990102206.png" alt="1695990102206"></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695990133905.png" alt="1695990133905"></p>
<h4 id="3-1-4-节点信息"><a href="#3-1-4-节点信息" class="headerlink" title="3.1.4 节点信息"></a>3.1.4 节点信息</h4><p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1695990148101.png" alt="1695990148101"></p>
<h4 id="3-1-5-代码演示"><a href="#3-1-5-代码演示" class="headerlink" title="3.1.5 代码演示"></a>3.1.5 代码演示</h4><ul>
<li>html</li>
</ul>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">ul</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">li</span> <span class="attr">id</span>=<span class="string">&quot;l1&quot;</span>&gt;</span>张三<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">li</span> <span class="attr">id</span>=<span class="string">&quot;l2&quot;</span>&gt;</span>李四<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">li</span>&gt;</span>王五<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;&quot;</span> <span class="attr">class</span>=<span class="string">&quot;a1&quot;</span>&gt;</span>thr<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">span</span>&gt;</span>hhh<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;&quot;</span> <span class="attr">title</span>=<span class="string">&quot;a2&quot;</span>&gt;</span>百度<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;d1&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">span</span>&gt;</span></span><br><span class="line">            hahaha</span><br><span class="line">        <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span> <span class="attr">id</span>=<span class="string">&quot;p1&quot;</span> <span class="attr">class</span>=<span class="string">&quot;p1&quot;</span>&gt;</span>hehehe<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>py</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过解析本地文件来学习bs4的基础语法</span></span><br><span class="line"><span class="comment"># 记得指定编码格式, 默认打开的文件编码格式是 gbk</span></span><br><span class="line">soup = BeautifulSoup(<span class="built_in">open</span>(<span class="string">&#x27;06_bs4.html&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>), <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="comment"># print(soup)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (一) 节点定位</span></span><br><span class="line"><span class="comment"># 1. 根据标签名字查找节点</span></span><br><span class="line"><span class="comment"># 找到的是第一个符合条件的数据</span></span><br><span class="line"><span class="built_in">print</span>(soup.a)  <span class="comment"># &lt;a href=&quot;&quot;&gt;thr&lt;/a&gt;</span></span><br><span class="line"><span class="comment"># 获取标签的属性和属性值</span></span><br><span class="line"><span class="built_in">print</span>(soup.a.attrs)  <span class="comment"># &#123;&#x27;href&#x27;: &#x27;&#x27;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. bs4 的一些函数</span></span><br><span class="line"><span class="comment"># 2.1 find</span></span><br><span class="line"><span class="comment"># 2.1.1 返回第一个符合条件的数据</span></span><br><span class="line"><span class="built_in">print</span>(soup.find(<span class="string">&#x27;a&#x27;</span>))  <span class="comment"># &lt;a href=&quot;&quot;&gt;thr&lt;/a&gt;</span></span><br><span class="line"><span class="comment"># 2.1.2 根据属性的值找到对应的标签对象</span></span><br><span class="line"><span class="built_in">print</span>(soup.find(<span class="string">&#x27;a&#x27;</span>, title=<span class="string">&#x27;a2&#x27;</span>))</span><br><span class="line"><span class="comment"># 2.1.3 由于 class 与关键字冲突, 因此加个下划线以示区别</span></span><br><span class="line"><span class="built_in">print</span>(soup.find(<span class="string">&#x27;a&#x27;</span>, class_=<span class="string">&#x27;a1&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.2 find_all</span></span><br><span class="line"><span class="comment"># 2.2.1 返回包含所有符合条件的标签对象的列表</span></span><br><span class="line"><span class="built_in">print</span>(soup.find_all(<span class="string">&#x27;a&#x27;</span>))  <span class="comment"># [&lt;a class=&quot;a1&quot; href=&quot;&quot;&gt;thr&lt;/a&gt;, &lt;a href=&quot;&quot; title=&quot;a2&quot;&gt;百度&lt;/a&gt;]</span></span><br><span class="line"><span class="comment"># 2.2.2 如果想获取的是多个标签的数据, 需要在find_all参数中添加列表的数据</span></span><br><span class="line"><span class="built_in">print</span>(soup.find_all([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;span&#x27;</span>]))</span><br><span class="line"><span class="comment"># 2.2.3 limit 参数可以查找前几个数据</span></span><br><span class="line"><span class="built_in">print</span>(soup.find_all(<span class="string">&#x27;li&#x27;</span>, limit=<span class="number">2</span>))  <span class="comment"># [&lt;li&gt;张三&lt;/li&gt;, &lt;li&gt;李四&lt;/li&gt;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.3 select(推荐, 但一般情况下会结合上面两种使用)</span></span><br><span class="line"><span class="comment"># 2.3.1 select 方法返回的是一个列表 并且返回多个数据</span></span><br><span class="line"><span class="built_in">print</span>(soup.select(<span class="string">&#x27;a&#x27;</span>))  <span class="comment"># [&lt;a class=&quot;a1&quot; href=&quot;&quot;&gt;thr&lt;/a&gt;, &lt;a href=&quot;&quot; title=&quot;a2&quot;&gt;百度&lt;/a&gt;]</span></span><br><span class="line"><span class="comment"># 2.3.2 可以通过 . 代表 class, 用类选择器的方法进行筛选</span></span><br><span class="line"><span class="built_in">print</span>(soup.select(<span class="string">&#x27;.a1&#x27;</span>))  <span class="comment"># &lt;a class=&quot;a1&quot; href=&quot;&quot;&gt;thr&lt;/a&gt;]</span></span><br><span class="line"><span class="comment"># 2.3.3 也可以用属性选择器进行筛选和查找（用的多些）</span></span><br><span class="line"><span class="built_in">print</span>(soup.select(<span class="string">&#x27;#l1&#x27;</span>))  <span class="comment"># [&lt;li id=&quot;l1&quot;&gt;张三&lt;/li&gt;]</span></span><br><span class="line"><span class="comment"># 2.3.4.1 查找 li 标签中有 id 属性的标签</span></span><br><span class="line"><span class="built_in">print</span>(soup.select(<span class="string">&#x27;li[id]&#x27;</span>))  <span class="comment"># [&lt;li id=&quot;l1&quot;&gt;张三&lt;/li&gt;, &lt;li id=&quot;l2&quot;&gt;李四&lt;/li&gt;]</span></span><br><span class="line"><span class="comment"># 2.3.4.2 查找 li 标签中 id 为 l2 的标签</span></span><br><span class="line"><span class="built_in">print</span>(soup.select(<span class="string">&#x27;li[id=&quot;l2&quot;]&#x27;</span>))  <span class="comment"># [&lt;li id=&quot;l2&quot;&gt;李四&lt;/li&gt;]</span></span><br><span class="line"><span class="comment"># 2.3.5 层级选择器 获取div下面的li的方式</span></span><br><span class="line"><span class="comment"># 2.3.5.1 后代选择器</span></span><br><span class="line"><span class="built_in">print</span>(soup.select(<span class="string">&#x27;div li&#x27;</span>))  <span class="comment"># [&lt;li id=&quot;l1&quot;&gt;张三&lt;/li&gt;, &lt;li id=&quot;l2&quot;&gt;李四&lt;/li&gt;, &lt;li&gt;王五&lt;/li&gt;]</span></span><br><span class="line"><span class="comment"># 2.3.5.2 子代选择器 注意: 很多的计算机编程语言中, 如果不加空格不会输出内容, 但在bs4中, 不会报错, 也会显示内容</span></span><br><span class="line"><span class="built_in">print</span>(soup.select(<span class="string">&#x27;div &gt; ul &gt; li&#x27;</span>))</span><br><span class="line"><span class="comment"># 2.3.2.3 找到a标签和li标签所有的对象</span></span><br><span class="line"><span class="built_in">print</span>(soup.select(<span class="string">&#x27;a,li&#x27;</span>))  <span class="comment"># [&lt;li id=&quot;l1&quot;&gt;张三&lt;/li&gt;, &lt;li id=&quot;l2&quot;&gt;李四&lt;/li&gt;, &lt;li&gt;王五&lt;/li&gt;, &lt;a class=&quot;a1&quot; href=&quot;&quot;&gt;thr&lt;/a&gt;, &lt;a href=&quot;&quot; title=&quot;a2&quot;&gt;百度&lt;/a&gt;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (二) 节点信息</span></span><br><span class="line"><span class="comment"># 1. 获取节点内容</span></span><br><span class="line">obj = soup.select(<span class="string">&#x27;#d1&#x27;</span>)[<span class="number">0</span>]  <span class="comment"># 返回一个列表</span></span><br><span class="line"><span class="comment"># 如果标签对象中只有内容, 那么 string 和 get_text() 都可以使用</span></span><br><span class="line"><span class="comment"># 但是如果标签对象中除了内容还有标签, 那么 string 就获取不到数据, 而 get_text() 是可以获取数据的</span></span><br><span class="line"><span class="comment"># 一般情况下推荐 get_text()</span></span><br><span class="line"><span class="built_in">print</span>(obj.string)  <span class="comment"># None</span></span><br><span class="line"><span class="built_in">print</span>(obj.get_text())  <span class="comment"># hahaha</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 节点的属性</span></span><br><span class="line"><span class="comment"># 注意 select 返回的是列表！！</span></span><br><span class="line">obj = soup.select(<span class="string">&#x27;#p1&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># name 是标签的名字</span></span><br><span class="line"><span class="built_in">print</span>(obj.name)  <span class="comment"># p</span></span><br><span class="line"><span class="comment"># attrs 是将属性值作为字典返回</span></span><br><span class="line"><span class="built_in">print</span>(obj.attrs)  <span class="comment"># &#123;&#x27;id&#x27;: &#x27;p1&#x27;, &#x27;class&#x27;: [&#x27;p1&#x27;]&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 获取节点属性 3中方式</span></span><br><span class="line">obj = soup.select(<span class="string">&#x27;#p1&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(obj.attrs.get(<span class="string">&#x27;class&#x27;</span>))  <span class="comment"># [&#x27;p1&#x27;] 推荐这种</span></span><br><span class="line"><span class="built_in">print</span>(obj.get(<span class="string">&#x27;class&#x27;</span>))  <span class="comment"># [&#x27;p1&#x27;]</span></span><br><span class="line"><span class="built_in">print</span>(obj[<span class="string">&#x27;class&#x27;</span>])  <span class="comment"># [&#x27;p1&#x27;]</span></span><br></pre></td></tr></table></figure>

<h3 id="3-2-bs4-爬取星巴克数据"><a href="#3-2-bs4-爬取星巴克数据" class="headerlink" title="3.2 bs4 爬取星巴克数据"></a>3.2 bs4 爬取星巴克数据</h3><blockquote>
<p>主要学习如何抓取服务器响应的文件</p>
<p>把菜单部分的图片以及产品的名字抓取并保存：</p>
<p><code>https://www.starbucks.com.cn/menu/</code></p>
</blockquote>
<ul>
<li><p>抓接口，看下只有一页，比较容易，找到接口：</p>
<p><code>https://www.starbucks.com.cn/menu/ </code></p>
</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696036608147.png" alt="1696036608147"></p>
<ul>
<li>先写 xpath 语法，再改成 bs4</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696037282802.png" alt="1696037282802"></p>
<ul>
<li>抓取图片有点难，需要分析并拼接url</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696038072885.png" alt="1696038072885"></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696038098710.png" alt="1696038098710"></p>
<ul>
<li>代码示例：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://www.starbucks.com.cn/menu/&#x27;</span></span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(url)</span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="comment"># print(content)  # 没做反爬, 直接拿到源码</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行解析</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 加载服务器响应文件</span></span><br><span class="line">soup = BeautifulSoup(content, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. xpath 语法: //ul[@class=&quot;grid padded-3 product&quot;]//strong/text()</span></span><br><span class="line">name_list = soup.select(<span class="string">&#x27;ul[class=&quot;grid padded-3 product&quot;] strong&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name <span class="keyword">in</span> name_list:</span><br><span class="line">    <span class="built_in">print</span>(name.string)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 爬取图片</span></span><br><span class="line">pic_list = soup.select(<span class="string">&#x27;ul[class=&quot;grid padded-3 product&quot;] div[class=&quot;preview circle&quot;]&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> pic <span class="keyword">in</span> pic_list:</span><br><span class="line">    <span class="comment"># 大佬的答案, 好强！！</span></span><br><span class="line">    completePicUrl = <span class="string">&#x27;https://www.starbucks.com.cn&#x27;</span>+pic.attrs.get(<span class="string">&#x27;style&#x27;</span>).split(<span class="string">&#x27;url(&quot;&#x27;</span>)[<span class="number">1</span>].split(<span class="string">&#x27;&quot;)&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="built_in">print</span>(completePicUrl)</span><br></pre></td></tr></table></figure>

<h1 id="Selenium"><a href="#Selenium" class="headerlink" title="Selenium"></a>Selenium</h1><blockquote>
<p>中文意思：[化学]硒</p>
</blockquote>
<h2 id="1-Selenium"><a href="#1-Selenium" class="headerlink" title="1. Selenium"></a>1. Selenium</h2><h3 id="1-1-介绍"><a href="#1-1-介绍" class="headerlink" title="1.1 介绍"></a>1.1 介绍</h3><ul>
<li><strong>什么是 Selenium</strong><ul>
<li>是一个用于 Web 应用程序测试的工具</li>
<li>其测试直接运行在浏览器中，就像真正的用户在操作一样</li>
<li>支持通过各种 driver 驱动真实浏览器完成测试</li>
<li>也支持无界面浏览器操作</li>
</ul>
</li>
<li><strong>为什么使用 selenium</strong><ul>
<li>模拟浏览器功能，自动执行网页中的js代码，实现<strong>动态加载</strong></li>
</ul>
</li>
<li><strong>缺点</strong>：原生selenium有点慢，之后加东西使它效率变快</li>
<li><strong>代码演示</strong>：</li>
</ul>
<blockquote>
<p>本次将要演示urllib获取京东的网页源码，从而说明使用的urllib获取京东的网页源码会缺失秒杀的一些数据，进而引入下一节将要使用的selenium </p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://www.jd.com/&quot;</span></span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(url)</span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure>

<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696400628402.png" alt="1696400628402"></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696400643464.png" alt="1696400643464"></p>
<blockquote>
<p>使用的urllib获取京东的网页源码，搜索秒杀中的数据，发现确实是少了秒杀的内容，因此，下一节将学习并说明selenium能驱动真实浏览器去获取数据，不会缺少内容 </p>
</blockquote>
<h3 id="1-2-基本使用"><a href="#1-2-基本使用" class="headerlink" title="1.2 基本使用"></a>1.2 基本使用</h3><h4 id="1-2-1-安装-selenium"><a href="#1-2-1-安装-selenium" class="headerlink" title="1.2.1 安装 selenium"></a>1.2.1 安装 selenium</h4><ul>
<li><p><strong>谷歌浏览器</strong>：</p>
<ul>
<li><p>驱动地址下载：<code>http://chromedriver.storage.googleapis.com/index.html</code></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696401211274.png" alt="1696401211274"></p>
</li>
<li><p>谷歌驱动和谷歌浏览器版本之间的映射表：<code>http://blog.csdn.net/huilan_same/article/details/51896672</code></p>
</li>
<li><p>查看谷歌浏览器版本：谷歌浏览器右上角–&gt;帮助–&gt;关于</p>
<blockquote>
<p>貌似最高才 114，我这 116 的它还没有，暂时放弃</p>
</blockquote>
</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696401112871.png" alt="1696401112871"></p>
<ul>
<li><code>pip install selenium</code></li>
</ul>
</li>
<li><p>使用 <strong>Edge 浏览器</strong></p>
<ul>
<li><p>同理，先看浏览器版本号(帮助与反馈-&gt;关于)，再去 <code>https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/ </code> 中下载</p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696401400568.png" alt="1696401400568"></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696401510188.png" alt="1696401510188"></p>
</li>
<li><p>解压文件：</p>
</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696401624552.png" alt="1696401624552"></p>
<ul>
<li>放在代码目录下并安装：</li>
</ul>
<blockquote>
<p>注意selenium版本和urllib3版本不兼容的问题！</p>
<p>弹幕大佬建议：在selenium后面加个&#x3D;&#x3D;3.141.0，否则后面会因为下载的selenium版本过高操作不同，个人认为高版本不好用，用法还得自己找</p>
</blockquote>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696401889003.png" alt="1696401889003"></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696401875922.png" alt="1696401875922"></p>
</li>
</ul>
<h4 id="1-2-2-版本兼容问题解决"><a href="#1-2-2-版本兼容问题解决" class="headerlink" title="1.2.2 版本兼容问题解决"></a>1.2.2 版本兼容问题解决</h4><ul>
<li>由于版本不兼容的问题，这里还需要改下，我改了两个位置<ul>
<li>selenium 改成 3.141.0 版本</li>
<li>urllib3 改成 1.2.6.2 版本</li>
</ul>
</li>
<li>修改参考如下步骤：</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696402920101.png" alt="1696402920101"></p>
<h4 id="1-2-3-代码演示"><a href="#1-2-3-代码演示" class="headerlink" title="1.2.3 代码演示"></a>1.2.3 代码演示</h4><ul>
<li><strong>访问百度</strong>：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 导入 selenium</span></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 创建浏览器操作对象</span></span><br><span class="line">path = <span class="string">&quot;msedgedriver.exe&quot;</span>  <span class="comment"># 驱动文件的路径</span></span><br><span class="line">browser = webdriver.Edge(path)  <span class="comment"># 创建浏览器</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 访问网站</span></span><br><span class="line"><span class="comment"># 访问地址</span></span><br><span class="line">url = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line"><span class="comment"># 浏览器打开网址</span></span><br><span class="line">browser.get(url)</span><br></pre></td></tr></table></figure>

<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696403107071.png" alt="1696403107071"></p>
<ul>
<li><strong>访问京东并获取带有秒杀界面的源码</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 导入 selenium</span></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 创建浏览器操作对象</span></span><br><span class="line">path = <span class="string">&#x27;msedgedriver.exe&#x27;</span>  <span class="comment"># 驱动文件的路径</span></span><br><span class="line">browser = webdriver.Edge(path)  <span class="comment"># 创建浏览器</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 访问网站</span></span><br><span class="line">url = <span class="string">&#x27;https://www.jd.com&#x27;</span></span><br><span class="line">browser.get(url)</span><br><span class="line"><span class="comment"># page_source 获取网页源码</span></span><br><span class="line">content = browser.page_source</span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure>

<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696403258751.png" alt="1696403258751"></p>
<h3 id="1-3-元素定位"><a href="#1-3-元素定位" class="headerlink" title="1.3 元素定位"></a>1.3 元素定位</h3><blockquote>
<p>如果我们需要使用程序在百度（<code>https://www.baidu.com/</code>）中输入“周杰伦”，然后点击“百度一下”，会跳到一个新的页面。其中，使用程序找到“百度一下”的过程称为元素定位</p>
</blockquote>
<h4 id="1-3-1-元素定位的定义与方法"><a href="#1-3-1-元素定位的定义与方法" class="headerlink" title="1.3.1 元素定位的定义与方法"></a>1.3.1 元素定位的定义与方法</h4><p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696403449710.png" alt="1696403449710"></p>
<h4 id="1-3-2-代码演示"><a href="#1-3-2-代码演示" class="headerlink" title="1.3.2 代码演示"></a>1.3.2 代码演示</h4><blockquote>
<p>不过这是老版本的，新版本好像把这些都结合成一个方法了</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建浏览器操作对象</span></span><br><span class="line">path = <span class="string">&#x27;msedgedriver.exe&#x27;</span>  <span class="comment"># 驱动文件的路径</span></span><br><span class="line">browser = webdriver.Edge(path)  <span class="comment"># 创建浏览器</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 访问网站</span></span><br><span class="line">url = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line">browser.get(url)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 元素定位</span></span><br><span class="line"><span class="comment"># 1. 根据 id 找到对象  &lt;input type=&quot;submit&quot; id=&quot;su&quot; value=&quot;百度一下&quot; class=&quot;bg s_btn&quot;&gt;</span></span><br><span class="line">button = browser.find_element_by_id(<span class="string">&#x27;su&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(button)  <span class="comment"># &lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;f8da6a0d36bcf1b411dbbd04fb181d99&quot;, element=&quot;1F0CAAC086FFF88546C0873E34B579E2_element_6&quot;)&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 根据标签属性的属性值来获取对象 &lt;input id=&quot;kw&quot; name=&quot;wd&quot; class=&quot;s_ipt&quot; value=&quot;&quot; maxlength=&quot;255&quot; autocomplete=&quot;off&quot;&gt;</span></span><br><span class="line">button = browser.find_element_by_name(<span class="string">&#x27;wd&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(button)  <span class="comment"># selenium.webdriver.remote.webelement.WebElement (session=&quot;0ec1958b0e548f1ff0d1c001c0b604f2&quot;, element=&quot;857A99072AE0926284925BCCD1F8543E_element_5&quot;)&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 根据 xpath 语句获取对象</span></span><br><span class="line">button = browser.find_elements_by_xpath(<span class="string">&#x27;//input[@id=&quot;su&quot;]&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(button)  <span class="comment"># [&lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;e8f80626515e815272fc55fb2e8bf237&quot;, element=&quot;663F3737137A55001C2D941F6E5BCB8F_element_6&quot;)&gt;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 根据标签的名字来获取对象</span></span><br><span class="line">button = browser.find_elements_by_tag_name(<span class="string">&#x27;input&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(button)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 使用 bs4 的语法来获取对象</span></span><br><span class="line">button = browser.find_elements_by_css_selector(<span class="string">&#x27;#su&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(button)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 根据链接的文本来获取对象</span></span><br><span class="line">button = browser.find_element_by_link_text(<span class="string">&#x27;新闻&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(button)  <span class="comment"># &lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;9f4847fd6b8da07b16d46fa265b7047c&quot;, element=&quot;E9A97B94E3D31089587AAF9916E657BF_element_25&quot;)&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="1-4-元素信息"><a href="#1-4-元素信息" class="headerlink" title="1.4 元素信息"></a>1.4 元素信息</h3><h4 id="1-4-1-访问元素信息"><a href="#1-4-1-访问元素信息" class="headerlink" title="1.4.1 访问元素信息"></a>1.4.1 访问元素信息</h4><ul>
<li>获取元素属性： <code>.get_attribute(&#39;class&#39;)</code></li>
<li>获取元素文本：<code>text</code> </li>
<li>获取标签名：<code>tag_name</code></li>
</ul>
<h4 id="1-4-2-代码演示"><a href="#1-4-2-代码演示" class="headerlink" title="1.4.2 代码演示"></a>1.4.2 代码演示</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">path = <span class="string">&#x27;msedgedriver.exe&#x27;</span></span><br><span class="line">browser = webdriver.Edge(path)</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://www.baidu.com&#x27;</span></span><br><span class="line">browser.get(url)</span><br><span class="line"></span><br><span class="line"><span class="comment"># selenium 访问元素信息</span></span><br><span class="line"><span class="built_in">input</span> = browser.find_element_by_id(<span class="string">&#x27;su&#x27;</span>)</span><br><span class="line"><span class="comment"># 1. 获取元素属性</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>.get_attribute(<span class="string">&#x27;class&#x27;</span>))  <span class="comment"># bg s_btn</span></span><br><span class="line"><span class="comment"># 2. 获取标签名</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>.tag_name)  <span class="comment"># input</span></span><br><span class="line"><span class="comment"># 3. 获取元素文本</span></span><br><span class="line">a = browser.find_element_by_link_text(<span class="string">&#x27;新闻&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(a.text)  <span class="comment"># 新闻</span></span><br></pre></td></tr></table></figure>

<h3 id="1-5-selenium-的交互"><a href="#1-5-selenium-的交互" class="headerlink" title="1.5 selenium 的交互"></a>1.5 selenium 的交互</h3><h4 id="1-5-1-交互"><a href="#1-5-1-交互" class="headerlink" title="1.5.1 交互"></a>1.5.1 交互</h4><ul>
<li>点击：<code>click()</code></li>
<li>输入：<code>send_keys()</code></li>
<li>后退操作：<code>browser.back()</code></li>
<li>前进操作：<code>browser.forword()</code></li>
<li>模拟JS滚动： <code>js=&#39;document.documentElement.scrollTop=100000&#39;</code>   <code>browser.execute_script(js)</code></li>
<li>执行js代a码 获取网页代码：<code>page_source</code></li>
<li>退出：<code>browser.quit()</code></li>
</ul>
<h4 id="1-5-2-代码演示"><a href="#1-5-2-代码演示" class="headerlink" title="1.5.2 代码演示"></a>1.5.2 代码演示</h4><blockquote>
<p>本次需要通过程序使浏览器使用百度搜索“周杰伦”，然后点到第2页，再使用一下后退、前进操作，然后再滚动到页末 </p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建浏览器对象</span></span><br><span class="line">path = <span class="string">&#x27;msedgedriver.exe&#x27;</span></span><br><span class="line">browser = webdriver.Edge(path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># url</span></span><br><span class="line">url = <span class="string">&#x27;http://www.baidu.com&#x27;</span></span><br><span class="line">browser.get(url)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">time.sleep(<span class="number">2</span>)  <span class="comment"># 睡眠两秒</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取文本框的对象</span></span><br><span class="line"><span class="built_in">input</span> = browser.find_element_by_id(<span class="string">&#x27;kw&#x27;</span>)</span><br><span class="line"><span class="comment"># 在文本框中输入文本</span></span><br><span class="line"><span class="built_in">input</span>.send_keys(<span class="string">&#x27;周杰伦&#x27;</span>)</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取点击按钮</span></span><br><span class="line">button = browser.find_element_by_id(<span class="string">&#x27;su&#x27;</span>)</span><br><span class="line"><span class="comment"># 点击按钮</span></span><br><span class="line">button.click()</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 滑倒顶部</span></span><br><span class="line">js_bottom = <span class="string">&#x27;document.documentElement.scrollTop=100000&#x27;</span></span><br><span class="line">browser.execute_script(js_bottom)</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取下一页的按钮</span></span><br><span class="line"><span class="built_in">next</span> = browser.find_element_by_xpath(<span class="string">&#x27;//a[@class=&quot;n&quot;]&#x27;</span>)</span><br><span class="line"><span class="comment"># 点击下一页</span></span><br><span class="line"><span class="built_in">next</span>.click()</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 回到上一页</span></span><br><span class="line">browser.back()</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 回去</span></span><br><span class="line">browser.forward()</span><br><span class="line">time.sleep(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 退出</span></span><br><span class="line">browser.quit()</span><br></pre></td></tr></table></figure>

<h2 id="2-Phantomjs"><a href="#2-Phantomjs" class="headerlink" title="2. Phantomjs"></a>2. Phantomjs</h2><blockquote>
<p>在前面的学习中，发现Selenium，每次执行过程中都需打开浏览器、关闭浏览器、中间还有一堆操作，这是因为它有页面，而页面里面会有js、css等等很多文件，因此打开页面会导致代码的性能很慢</p>
<p>因此提出Phantomjs、Chrome handless,目前Phantomjs已逐渐淘汰，<strong>这里就不学了我</strong></p>
</blockquote>
<h3 id="2-1-介绍"><a href="#2-1-介绍" class="headerlink" title="2.1 介绍"></a>2.1 介绍</h3><ul>
<li>是一个无界面浏览器</li>
<li>支持页面元素查找，js 的执行等</li>
<li>由于不进行 css 和 gui 渲染，运行效率比真实的浏览器要快的多</li>
</ul>
<h3 id="2-2-如何使用-Phantomjs"><a href="#2-2-如何使用-Phantomjs" class="headerlink" title="2.2 如何使用 Phantomjs"></a>2.2 如何使用 Phantomjs</h3><ul>
<li>获取Phantomjs.exe文件路径path </li>
<li>browser&#x3D; webdriver.PhantomJs(path) </li>
<li>browser.get(url)</li>
</ul>
<blockquote>
<p>扩展：保存屏幕快照：browser.save_screenshot(‘baidu.png’) </p>
</blockquote>
<h2 id="3-Chrome-handless"><a href="#3-Chrome-handless" class="headerlink" title="3. Chrome handless"></a>3. Chrome handless</h2><ul>
<li><strong>基本配置</strong>：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver  <span class="comment"># 导入selenium库</span></span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.chrome.options <span class="keyword">import</span> Options  <span class="comment"># 导入浏览器设置相关的类</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 无可视化界面设置</span></span><br><span class="line">chrome_options = Options()</span><br><span class="line"><span class="comment"># 使用无头模式</span></span><br><span class="line">chrome_options.add_argument(<span class="string">&#x27;--headless&#x27;</span>)</span><br><span class="line"><span class="comment"># 禁用GPU，防止无头模式出现莫名的BUG</span></span><br><span class="line">chrome_options.add_argument(<span class="string">&#x27;--disable-gpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">path = <span class="string">r&#x27;C:\Program Files\Google\Chrome\Application\chrome.exe&#x27;</span></span><br><span class="line">chrome_options.binary_location = path</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome(chrome_options=chrome_options)</span><br><span class="line">browser.get(<span class="string">&#x27;http://www/baidu.com/&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="requests"><a href="#requests" class="headerlink" title="requests"></a>requests</h1><blockquote>
<p>只属于 python？其他编程语言没有？</p>
</blockquote>
<h2 id="1-基本使用"><a href="#1-基本使用" class="headerlink" title="1. 基本使用"></a>1. 基本使用</h2><ul>
<li><p><strong>文档</strong></p>
<ul>
<li>官方文档：    <code>https://requests.readthedocs.io/projects/cn/zh_CN/latest</code></li>
<li>快速上手    <code>https://requests.readthedocs.io/projects/cn/zh_CN/latest/user/quickstart.html</code></li>
</ul>
</li>
<li><p><strong>安装</strong></p>
<ul>
<li><code>pip install requests</code></li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696039537783.png" alt="1696039537783"></p>
</li>
<li><p><strong>response 的属性以及类型</strong></p>
</li>
</ul>
<table>
<thead>
<tr>
<th>类型</th>
<th>models.Response</th>
</tr>
</thead>
<tbody><tr>
<td>r.text</td>
<td>获取网站源码</td>
</tr>
<tr>
<td>r.encoding</td>
<td>访问或定制编码方式</td>
</tr>
<tr>
<td>r.url</td>
<td>获取请求的url</td>
</tr>
<tr>
<td>r.content</td>
<td>响应的字节类型</td>
</tr>
<tr>
<td>r.status_code</td>
<td>响应的状态码</td>
</tr>
<tr>
<td>r.headers</td>
<td>响应的头信息</td>
</tr>
</tbody></table>
<ul>
<li><strong>代码示例</strong>：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://www.baidu.com&#x27;</span></span><br><span class="line">response = requests.get(url=url)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 一个类型和六个属性</span></span><br><span class="line"><span class="comment"># Response 类型, 和 urllib 不一样(HTTPResponse类型)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(response))  <span class="comment"># &lt;class &#x27;requests.models.Response&#x27;&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 六个属性</span></span><br><span class="line"><span class="comment"># 1. encoding 设置响应的编码格式</span></span><br><span class="line">response.encoding = <span class="string">&#x27;utf-8&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. text 以字符串形式返回网页的源码</span></span><br><span class="line"><span class="built_in">print</span>(response.text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 获取请求的 url</span></span><br><span class="line"><span class="built_in">print</span>(response.url)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 返回的是二进制的数据</span></span><br><span class="line"><span class="built_in">print</span>(response.content)  <span class="comment"># b&#x27;&lt;!DOCTYPE html&gt;\r\n&lt;!--STATUS OK--...</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 返回响应的状态码</span></span><br><span class="line"><span class="built_in">print</span>(response.status_code)  <span class="comment"># 200</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 获取响应头信息</span></span><br><span class="line"><span class="built_in">print</span>(response.headers)  <span class="comment"># &#123;&#x27;Cache-Control&#x27;: &#x27;private, no-cache, no-store...</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="2-get-请求"><a href="#2-get-请求" class="headerlink" title="2. get 请求"></a>2. get 请求</h2><ul>
<li><strong>总结</strong>：<ul>
<li>参数使用 params 传递</li>
<li>参数无需 urlencode 编码</li>
<li>不需要请求对象的定制</li>
<li>请求资源路径中的<code>?</code>可以加也可以不加</li>
</ul>
</li>
<li><strong>代码示例</strong>：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># urllib VS requests</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. urllib</span></span><br><span class="line"><span class="comment"># 1.1 一个类型六个方法</span></span><br><span class="line"><span class="comment"># 1.2 get 请求</span></span><br><span class="line"><span class="comment"># 1.3 post 请求</span></span><br><span class="line"><span class="comment"># 1.4 ajax 的 get 请求</span></span><br><span class="line"><span class="comment"># 1.5 ajax 的 post 请求</span></span><br><span class="line"><span class="comment"># 1.6 cookie 登录</span></span><br><span class="line"><span class="comment"># 1.7 代理</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. request</span></span><br><span class="line"><span class="comment"># 2.1 一个类型六个属性</span></span><br><span class="line"><span class="comment"># 2.2 get 请求</span></span><br><span class="line"><span class="comment"># 2.3 post 请求</span></span><br><span class="line"><span class="comment"># 2.4 代理</span></span><br><span class="line"><span class="comment"># 2.5 cookie 验证码</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://www.baidu.com/s?&#x27;</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Cookie&#x27;</span>: <span class="string">&#x27;BDUSS=E5yeFZUSFRyTUxzUEhVbXhzUkZOV3lyeDlGLUMyVWFranBDNlRiV21tTWlnRDVrSVFBQUFBJCQAAAAAAAAAAAEAAAB~ymGB06O7qGNhbzAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACLzFmQi8xZkT; BDUSS_BFESS=E5yeFZUSFRyTUxzUEhVbXhzUkZOV3lyeDlGLUMyVWFranBDNlRiV21tTWlnRDVrSVFBQUFBJCQAAAAAAAAAAAEAAAB~ymGB06O7qGNhbzAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACLzFmQi8xZkT; BIDUPSID=B26B49048A0C9099B1456DF64F0279FF; PSTM=1684546051; BAIDUID=C70948D5D545EED0115F390D9D6C8143:SL=0:NR=10:FG=1; BD_UPN=12314753; BDORZ=B490B5EBF6F3CD402E515D22BCDA1598; BDRCVFR[feWj1Vr5u3D]=I67x6TjHwwYf0; delPer=0; BD_CK_SAM=1; PSINO=5; BAIDUID_BFESS=C70948D5D545EED0115F390D9D6C8143:SL=0:NR=10:FG=1; BA_HECTOR=ag01ag2g8k2hak81242k81001ihcet51p; B64_BOT=1; RT=&quot;z=1&amp;dm=baidu.com&amp;si=bee5a4dd-dfb0-43a8-8226-878c0904dd53&amp;ss=ln47d4cw&amp;sl=0&amp;tt=0&amp;bcn=https%3A%2F%2Ffclog.baidu.com%2Flog%2Fweirwood%3Ftype%3Dperf&amp;ul=1xd&amp;hd=1xx&quot;; COOKIE_SESSION=0_0_0_0_1_0_1_0_0_0_0_0_0_0_3_0_1695967725_0_1695967722%7C1%230_0_1695967722%7C1; ZFY=jKLYva:AwW:AlQpwrTh6Gt4SREDbR7NGeps2ei6L3zLXg:C; H_PS_PSSID=39323_39353_39399_39396_39407_39097_39412_39436_39358_39308_39375_39233_39406_26350_39219_22158_39427; baikeVisitId=cff92722-9312-4f8d-8d48-c7ba4ffa672e; sug=3; sugstore=0; ORIGIN=2; bdime=21111; H_PS_645EC=30ackYSFvlTVDOWoTBZDrGzNnqQmMHFCdPeK0%2BLRZ1OYuKcXF7ps3bKsk04&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;wd&#x27;</span>: <span class="string">&#x27;北京&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># requests.get 的参数有三个</span></span><br><span class="line"><span class="comment"># url:请求资源路径  params 参数 kwargs:字典</span></span><br><span class="line">response = requests.get(url=url, params=data, headers=headers)</span><br><span class="line">content = response.text  <span class="comment"># 注意这是属性</span></span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure>

<h2 id="3-post-请求"><a href="#3-post-请求" class="headerlink" title="3. post 请求"></a>3. post 请求</h2><ul>
<li>抓取百度翻译  <code>https://fanyi.baidu.com/sug </code></li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696041178762.png" alt="1696041178762"></p>
<ul>
<li><strong>代码实现</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://fanyi.baidu.com/sug&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">   <span class="string">&#x27;kw&#x27;</span>: <span class="string">&#x27;math&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># requests.post 该句使用到的参数说明:</span></span><br><span class="line"><span class="comment"># url请求地址 data请求参数 kwargs字典</span></span><br><span class="line">response = requests.post(url=url, data=data, headers=headers)</span><br><span class="line"></span><br><span class="line">content = response.text</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line">obj = json.loads(content.encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(obj)  <span class="comment"># &#123;&#x27;errno&#x27;: 0, &#x27;data&#x27;: [&#123;&#x27;k&#x27;: &#x27;math&#x27;, &#x27;v&#x27;: &#x27;n. 数...</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>总结</strong>：<ul>
<li>post请求 是不需要编解码</li>
<li>post请求的参数是data</li>
<li>不需要请求对象的定制</li>
</ul>
</li>
</ul>
<h2 id="4-代理"><a href="#4-代理" class="headerlink" title="4. 代理"></a>4. 代理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置其他ip</span></span><br><span class="line">proxy=&#123;</span><br><span class="line">    <span class="string">&#x27;http&#x27;</span>:<span class="string">&#x27;58.20.184.187:9091&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response = requests.get(url=url, params=data, headers=headers,proxies=proxy)</span><br></pre></td></tr></table></figure>

<h2 id="5-cookie-定制"><a href="#5-cookie-定制" class="headerlink" title="5. cookie 定制"></a>5. cookie 定制</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">cookie登陆古诗文网（含验证码）</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 通过登陆  然后进入到主页面</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过找登陆接口我们发现 登陆的时候需要的参数很多</span></span><br><span class="line"><span class="comment"># __VIEWSTATE: wzavkIiUpeGeXT-Gu4jEWSBcHAneSt4SJdDa3y/PEP5sDZuLEWgE1r37kEQzlJ/pVVbYYMe7vrMvtm3NUmkX2KGAuPYULzyiZDcfhry5nbmFCtGY/RrDbqJIDMu0KDOYRMeQRs/Xwv2vH/1ZpkEoSK0lGoA0=</span></span><br><span class="line"><span class="comment"># __VIEWSTATEGENERATOR: C93BE1AE</span></span><br><span class="line"><span class="comment"># from: http://so.gushiwen.cn/user/collect.aspx</span></span><br><span class="line"><span class="comment"># email: cney6tcn@linshiyouxiang.net</span></span><br><span class="line"><span class="comment"># pwd: 8YW8GYET78933ETR</span></span><br><span class="line"><span class="comment"># code: 32GV</span></span><br><span class="line"><span class="comment"># denglu: 登录</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 我们观察到_VIEWSTATE   __VIEWSTATEGENERATOR  code是一个可以变化的量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 难点:(1)_VIEWSTATE   __VIEWSTATEGENERATOR  一般情况看不到的数据 都是在页面的源码中</span></span><br><span class="line"><span class="comment">#     我们观察到这两个数据在页面的源码中 所以我们需要获取页面的源码 然后进行解析就可以获取了</span></span><br><span class="line"><span class="comment">#     (2)验证码</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这是登陆页面的url地址</span></span><br><span class="line">url = <span class="string">&#x27;https://so.gushiwen.cn/user/login.aspx?from=http://so.gushiwen.cn/user/collect.a&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) Ap-pleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Mobile Safari/537.36 Edg/115.0.1901.200&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line">response = requests.get(url=url, headers=headers)</span><br><span class="line">content = response.text</span><br><span class="line"><span class="built_in">print</span>(content)  <span class="comment"># 测试代码，验证能否获取网页源码</span></span><br></pre></td></tr></table></figure>

<h1 id="scrapy"><a href="#scrapy" class="headerlink" title="scrapy"></a>scrapy</h1><h2 id="1-srcapy-安装"><a href="#1-srcapy-安装" class="headerlink" title="1. srcapy 安装"></a>1. srcapy 安装</h2><h3 id="1-1-什么是-srcapy"><a href="#1-1-什么是-srcapy" class="headerlink" title="1.1 什么是 srcapy"></a>1.1 什么是 srcapy</h3><ul>
<li>scray 是一个为了爬取网站数据，提取结构性数据而编写的<strong>应用框架</strong>。可以应用在包括数据挖掘、信息处理或存储历史数据等一系列的程序中。   </li>
<li>什么是结构性数据？<ul>
<li>结构性就是类似的具有相同特征的东西，里面的数据就是结构性数据。   </li>
<li>选中一本书进行定位（即在某本书处打开检查），发现这些书的信息有一个相同的结构，比如书名都在结构“&#x2F;html&#x2F;body&#x2F;div[6]&#x2F;div&#x2F;div[2]&#x2F;div[2]&#x2F;ul&#x2F;li&#x2F;div&#x2F;h3&#x2F;a”下，它们具有相同的结构，这就是结构性的例子。至于结构性数据，比如书名就是该结构下的数据。</li>
</ul>
</li>
<li>优点<ul>
<li>爬取速度快</li>
<li>代码简单好用</li>
</ul>
</li>
</ul>
<h3 id="1-2-srcapy-的安装"><a href="#1-2-srcapy-的安装" class="headerlink" title="1.2 srcapy 的安装"></a>1.2 srcapy 的安装</h3><ul>
<li>安装命令：<code>pip install scrapy </code></li>
</ul>
<h2 id="2-基本使用"><a href="#2-基本使用" class="headerlink" title="2. 基本使用"></a>2. 基本使用</h2><ul>
<li>使用步骤</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">1. 创建爬虫的项目     </span><br><span class="line">    scrapy startproject 项目名字</span><br><span class="line">    注意：项目的名字不允许使用数字开头   也不能包含中文</span><br><span class="line">2. 创建爬虫文件</span><br><span class="line">    要在spiders文件夹中去创建爬虫文件</span><br><span class="line"></span><br><span class="line">    进入spiders文件夹：cd 项目的名字\项目的名字\spiders，</span><br><span class="line">    - 本次演示使用的命令为    cd scrapy_baidu_091\scrapy_baidu_091\spiders</span><br><span class="line"></span><br><span class="line">    创建爬虫文件</span><br><span class="line">    scrapy genspider 爬虫的名字 要爬取的网页</span><br><span class="line">    eg:scrapy genspider baidu http://www.baidu.com</span><br><span class="line">3. 运行爬虫代码</span><br><span class="line">    scrapy crawl 爬虫的名字</span><br><span class="line">    eg:scrapy crawl baidu</span><br><span class="line">   注：在运行爬虫程序时，需注释掉文件“setting.py”中的“ROBOTSTXT_OBEY = True”,  </span><br><span class="line">       即不遵守君子协议</span><br></pre></td></tr></table></figure>

<ul>
<li>代码演示</li>
</ul>
<h1 id="补充知识"><a href="#补充知识" class="headerlink" title="补充知识"></a>补充知识</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1ha4y1H7sx?p=8&vd_source=ce97d263f08af76fc25ff49de530fe92">Day2 - 4.requests模块巩固深入案例之破解百度翻译_哔哩哔哩_bilibili</a> </p>
</blockquote>
<ul>
<li><strong>ajax</strong> 技术可以实现<strong>动态页面局部刷新</strong>，<strong>文件类型一般为xhr或fetch</strong></li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696077406694.png" alt="1696077406694"></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696077448796.png" alt="1696077448796"></p>
<ul>
<li>如果直接访问页面url，请求获取的静态页面<strong>缺少一些的局部数据</strong>，可以考虑<strong>所抓取的数据并不是通过 url 请求到的，可能是由 ajax 动态加载请求到的</strong>，可以进行下列方式验证：</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696078327549.png" alt="1696078327549"></p>
<h2 id="1-模拟登录"><a href="#1-模拟登录" class="headerlink" title="1. 模拟登录"></a>1. 模拟登录</h2><blockquote>
<p>爬取基于某些用户的用户信息</p>
</blockquote>
<ul>
<li><p><strong>cookie</strong>：用来让服务器端记录客户端的相关状态</p>
<ul>
<li><strong>不建议用手动cookie处理</strong>，即：通过f12里的抓包工具获取cookie值，将该值封装到 headers 中</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;Cookie&#x27;</span>: <span class="string">&#x27;xxx&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>自动处理</strong><ul>
<li>cookie 值的来源？&#x3D;&#x3D;&#x3D;&gt; 去页面抓包，找到响应头信息中包含 <code>Set-Cookie</code> 字段的请求</li>
<li>session 的会话对象：可以进行请求的发送；如果请求过程中产生了 cookie，则该 cookie 会被自动存储&#x2F;携带在该 session 对象中；那么之后就可以用这个已经存储了cookie的session对象发起请求</li>
</ul>
</li>
</ul>
</li>
<li><p>&#x3D;&#x3D;自动处理 cookie 进行模拟登录的流程&#x3D;&#x3D;：</p>
<ul>
<li>创建一个 session 对象：<code>requests.Session()</code></li>
<li>使用 session 对象进行模拟登录 post 请求的发送(cookie 就会被存储在session中)</li>
<li>session对象对个人主页对应的get请求进行发送(携带了 cookie)</li>
</ul>
</li>
</ul>
<h2 id="2-sign-反爬-js-逆向"><a href="#2-sign-反爬-js-逆向" class="headerlink" title="2. sign 反爬-js 逆向"></a>2. sign 反爬-js 逆向</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1tm4y1h7RL/?spm_id_from=333.337.search-card.all.click&vd_source=ce97d263f08af76fc25ff49de530fe92">【爬虫实战】有道翻译的JS逆向技巧，透彻讲解教你如何破解sign参数！_哔哩哔哩_bilibili</a> </p>
</blockquote>
<ul>
<li><strong>断点方式</strong>：<ul>
<li>xhr 断点  发包位置  加密参数之后断点<ul>
<li>对通用参数进行处理    往上找加密点</li>
</ul>
</li>
<li>dom 断点  执行某一个事件  加密参数之前断点<ul>
<li>往下找加密点</li>
</ul>
</li>
</ul>
</li>
<li>网页加密</li>
</ul>
<h2 id="3-浏览器调试-Dev-Tools"><a href="#3-浏览器调试-Dev-Tools" class="headerlink" title="3. 浏览器调试 Dev Tools"></a>3. 浏览器调试 Dev Tools</h2><blockquote>
<p>开发常用浏览器 Chrom，firefox</p>
<p>这里主要介绍 Chrom</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1KM4y1G7EF/?spm_id_from=333.337.search-card.all.click&vd_source=ce97d263f08af76fc25ff49de530fe92">【浏览器调试工具精讲】Chrome Dev Tools精讲，前端必看！_哔哩哔哩_bilibili</a> </p>
</blockquote>
<h3 id="3-1-各个-Tab-介绍"><a href="#3-1-各个-Tab-介绍" class="headerlink" title="3.1 各个 Tab 介绍"></a>3.1 各个 Tab 介绍</h3><ul>
<li>打开 Dev Tool<ul>
<li>菜单&gt;更多工具&gt;开发者工具</li>
<li>快捷键：F12</li>
</ul>
</li>
<li>打开命令菜单：<code>ctrl+shift+P</code></li>
<li><strong>常用的 Tab</strong><ul>
<li>Element</li>
<li>Console</li>
<li>Source</li>
<li>Network</li>
<li>Application</li>
</ul>
</li>
</ul>
<h3 id="3-2-控制台-Console"><a href="#3-2-控制台-Console" class="headerlink" title="3.2 控制台(Console)"></a>3.2 控制台(Console)</h3><ul>
<li>快捷键：<code>ctrl + Shift + J</code></li>
<li>控制台输入：<ul>
<li><code>$_</code> 可以返回上一条语句的执行结果</li>
</ul>
</li>
<li><code>$0</code> 可以返回上一个选择的DOM节点，以此类推，<code>$1</code> 就是上一个，<code>$2</code> 就是上上一个</li>
</ul>
<h3 id="3-3-JS-调试"><a href="#3-3-JS-调试" class="headerlink" title="3.3 JS 调试"></a>3.3 JS 调试</h3><ul>
<li>在 js 代码的某一行写上 <code>debugger</code>，回到页面运行时就会暂停在那行</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696155905278.png" alt="1696155905278"></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696155935075.png" alt="1696155935075"></p>
<ul>
<li>也可以直接<strong>点行号</strong>进行调试<ul>
<li>右侧 watch 部分还可以监测某一个变量</li>
</ul>
</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696156009157.png" alt="1696156009157"></p>
<ul>
<li>其他加断点方式</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696156367090.png" alt="1696156367090"></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696156516180.png" alt="1696156516180"></p>
<h3 id="3-4-Network"><a href="#3-4-Network" class="headerlink" title="3.4 Network"></a>3.4 Network</h3><ul>
<li>记住跳转页面前的上一个页面的请求，需要勾选 <code>Preserve log</code></li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696156691181.png" alt="1696156691181"></p>
<h2 id="4-案例：抓取网易云评论"><a href="#4-案例：抓取网易云评论" class="headerlink" title="4. 案例：抓取网易云评论"></a>4. 案例：抓取网易云评论</h2><blockquote>
<p>这个案例很完整，建议好好学！</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1q44y1N7hz/?p=50&spm_id_from=333.1007.top_right_bar_window_history.content.click&vd_source=ce97d263f08af76fc25ff49de530fe92">3 5 综合训练 抓取网易云音乐评论信息（6）_哔哩哔哩_bilibili</a> </p>
<p><code>https://music.163.com/#/song?id=1325905146 </code></p>
</blockquote>
<h3 id="4-1-分析接口"><a href="#4-1-分析接口" class="headerlink" title="4.1 分析接口"></a>4.1 分析接口</h3><ul>
<li>在f12抓包工具里的 XHR 选项下，可以找到获取评论的 post 接口：<code>https://music.163.com/weapi/comment/resource/comments/get?csrf_token=</code></li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696408535195.png" alt="1696408535195"></p>
<ul>
<li>可以看到需要有两个参数，但都是加密的</li>
</ul>
<blockquote>
<p>我们需要找到其 没加密之前是咋样的？加密的过程是咋样的？最后在程序里模拟其加密过程，加密完后再请求</p>
</blockquote>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696408515949.png" alt="1696408515949"></p>
<ul>
<li>在 <code>发起程序</code> 选项卡下有个请求调用堆栈，可以在这里查看所调用的 js：</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696408952124.png" alt="1696408952124"></p>
<h3 id="4-2-逆向-js"><a href="#4-2-逆向-js" class="headerlink" title="4.2 逆向 js"></a>4.2 逆向 js</h3><ul>
<li>尝试点击最上面的 js，也就是最后一次调用的 js，然后对代码进行分析</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696413885869.png" alt="1696413885869"></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696414122424.png" alt="1696414122424"></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696414266868.png" alt="1696414266868"></p>
<ul>
<li>找到加密的js，回去对其进行分析</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696414586163.png" alt="1696414586163"></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696414966073.png" alt="1696414966073"></p>
<ul>
<li>找到加密的函数，设断点，再进行分析</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696415569684.png" alt="1696415569684"></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696415827300.png" alt="1696415827300"></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696416034803.png" alt="1696416034803"></p>
<ul>
<li>继续执行，验证猜想</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696416158876.png" alt="1696416158876"></p>
<ul>
<li><p>得出结论：</p>
<ul>
<li><p>我们要的两个参数：</p>
<ul>
<li>params：encText</li>
<li>encSecKey：encSecKey</li>
</ul>
</li>
<li><p>都是由这个函数进行生成的：</p>
<p><code>var bKC6w = window.asrsea(JSON.stringify(i8a), bvh7a([&quot;流泪&quot;, &quot;强&quot;]), bvh7a(Re1x.md), bvh7a([&quot;爱心&quot;, &quot;女孩&quot;, &quot;惊恐&quot;, &quot;大笑&quot;]));</code></p>
</li>
</ul>
</li>
</ul>
<h3 id="4-3-对加密过程进行分析"><a href="#4-3-对加密过程进行分析" class="headerlink" title="4.3 对加密过程进行分析"></a>4.3 对加密过程进行分析</h3><ul>
<li>接下来分析下这个加密过程，直接 <code>ctrl+f</code> 找下这个 <code>window.asrsea</code> 是啥？除了这句话之外，整个代码里只有下面这个地方有这个参数：<code>window.asrsea = d</code></li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696416743521.png" alt="1696416743521"></p>
<ul>
<li>对 d 这个函数，结合加密语句进行分析</li>
</ul>
<p><code>var bKC6w = window.asrsea(JSON.stringify(i8a), bvh7a([&quot;流泪&quot;, &quot;强&quot;]), bvh7a(Re1x.md), bvh7a([&quot;爱心&quot;, &quot;女孩&quot;, &quot;惊恐&quot;, &quot;大笑&quot;]));</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">function d(d, e, f, g) &#123;  <span class="comment"># d: 数据 e: 010001 f: 很长的一个定值 g: &#x27;0CoJUm6Qyw8W8jud&#x27;</span></span><br><span class="line">    var h = &#123;&#125;</span><br><span class="line">      , i = a(<span class="number">16</span>);</span><br><span class="line">    <span class="keyword">return</span> h.encText = b(d, g),</span><br><span class="line">    h.encText = b(h.encText, i),</span><br><span class="line">    h.encSecKey = c(i, e, f),</span><br><span class="line">    h</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>可以发现，参数的 d 就是数据，后面的我们可以通过 console.log 获取其内容</p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696416995573.png" alt="1696416995573"></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696417194452.png" alt="1696417194452"></p>
</blockquote>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696418007641.png" alt="1696418007641"></p>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696418150552.png" alt="1696418150552"></p>
<h3 id="4-4-编写代码，得到结果"><a href="#4-4-编写代码，得到结果" class="headerlink" title="4.4 编写代码，得到结果"></a>4.4 编写代码，得到结果</h3><blockquote>
<p>太厉害了这个，好难</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 需求：</span></span><br><span class="line"><span class="comment"># 1. 找到未加密的参数                      # window.arsea(参数, xxx, xxx, xxx)</span></span><br><span class="line"><span class="comment"># 2. 想办法把参数进行加密(必须参考网易的逻辑), params =&gt; encText, encSecKey =&gt; encSecKey</span></span><br><span class="line"><span class="comment"># 3. 请求到网易, 拿到评论信息</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> Crypto.Cipher <span class="keyword">import</span> AES</span><br><span class="line"><span class="keyword">from</span> base64 <span class="keyword">import</span> b64encode</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://music.163.com/weapi/comment/resource/comments/get?csrf_token=&quot;</span></span><br><span class="line"><span class="comment"># 请求方式是 post</span></span><br><span class="line">data = &#123;  <span class="comment"># 通过 js 源码, 我们分析出来了真实的参数</span></span><br><span class="line">    <span class="string">&quot;rid&quot;</span>: <span class="string">&quot;R_SO_4_1325905146&quot;</span>,</span><br><span class="line">    <span class="string">&quot;threadId&quot;</span>: <span class="string">&quot;R_SO_4_1325905146&quot;</span>,</span><br><span class="line">    <span class="string">&quot;pageNo&quot;</span>: <span class="string">&quot;1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;pageSize&quot;</span>: <span class="string">&quot;20&quot;</span>,</span><br><span class="line">    <span class="string">&quot;cursor&quot;</span>: <span class="string">&quot;-1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;offset&quot;</span>: <span class="string">&quot;0&quot;</span>,</span><br><span class="line">    <span class="string">&quot;orderType&quot;</span>: <span class="string">&quot;1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;csrf_token&quot;</span>: <span class="string">&quot;&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 服务于d的</span></span><br><span class="line">f = <span class="string">&#x27;00e0b509f6259df8642dbc35662901477df22677ec152b5ff68ace615bb7b725152b3ab17a876aea8a5aa76d2e417629ec4ee341f56135fccf695280104e0312ecbda92557c93870114af6c9d05c4f7f0c3685b7a46bee255932575cce10b424d813cfe4875d3e82047b97ddef52741d546b8e289dc6935b3ece0462db0a22b8e7&#x27;</span></span><br><span class="line">g = <span class="string">&#x27;0CoJUm6Qyw8W8jud&#x27;</span></span><br><span class="line">e = <span class="string">&#x27;010001&#x27;</span></span><br><span class="line">i = <span class="string">&quot;SClpUDdZIpmWGncw&quot;</span>  <span class="comment"># 手动固定的</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_encSecKey</span>():  <span class="comment"># 由于 i 固定, 那么 encSecText 就是固定的, c() 函数的结果就是固定的</span></span><br><span class="line">    encSecKey = <span class="string">&quot;b40a2c971903961570378115316e7173a0d2a13532ebf67854866ffd90606842830f9713f2dbcb2db23e52c5ea5b9e48f1fed259ec15a82ab3d38228c90d88ced7885e69153a7cf4f0628983c0b427f15d4955f5afc34e0c332ca12cf47f359b7a68a5ab29bb774cd985638a733b824987a4548f8969fe2516e3de67b101426a&quot;</span></span><br><span class="line">    <span class="keyword">return</span> encSecKey</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_params</span>(<span class="params">data</span>):  <span class="comment"># 默认这里接收到的是字符串</span></span><br><span class="line">    first = enc_params(data, g)</span><br><span class="line">    second = enc_params(first, i)</span><br><span class="line">    <span class="keyword">return</span> second  <span class="comment"># 返回的就是 params</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 转化成 16 的倍数, 为下方的 AES 加密算法服务</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">to_16</span>(<span class="params">data</span>):</span><br><span class="line">    pad = <span class="number">16</span> - <span class="built_in">len</span>(data) % <span class="number">16</span></span><br><span class="line">    data += <span class="built_in">chr</span>(pad) * pad</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">enc_params</span>(<span class="params">data, key</span>):  <span class="comment"># 加密过程（最恶心的部分, 要还原js源码里的函数b）</span></span><br><span class="line">    <span class="comment"># 引入 AES 包后, 接下来进行 AES 加密</span></span><br><span class="line">    iv = <span class="string">&quot;0102030405060708&quot;</span></span><br><span class="line">    data = to_16(data)</span><br><span class="line">    aes = AES.new(key=key.encode(<span class="string">&quot;utf-8&quot;</span>), IV=iv.encode(<span class="string">&#x27;utf-8&#x27;</span>), mode=AES.MODE_CBC)</span><br><span class="line">    bs = aes.encrypt(data.encode(<span class="string">&#x27;utf-8&#x27;</span>))  <span class="comment"># 加密, 要求加密的内容的长度必须是16的倍数(而且补齐还是有逻辑的！), 涉及到AES加密的原理</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">str</span>(b64encode(bs), <span class="string">&quot;utf-8&quot;</span>)  <span class="comment"># 转化成字符串返回</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理加密过程</span></span><br><span class="line"><span class="comment"># var bKC6w = window.asrsea(JSON.stringify(i8a), bvh7a([&quot;流泪&quot;, &quot;强&quot;]), bvh7a(Re1x.md), bvh7a([&quot;爱心&quot;, &quot;女孩&quot;, &quot;惊恐&quot;, &quot;大笑&quot;]));</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">function a(a = 16) &#123;  # 返回随机的16位字符串</span></span><br><span class="line"><span class="string">    var d, e, b = &quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&quot;, c = &quot;&quot;;</span></span><br><span class="line"><span class="string">    for (d = 0; a &gt; d; d += 1)  # d 从 0-15, 循环 16 次, 产生 16 个随机的字母或数字</span></span><br><span class="line"><span class="string">        e = Math.random() * b.length,  # 随机数 假设1.2345</span></span><br><span class="line"><span class="string">        e = Math.floor(e),  # 取整 假设1</span></span><br><span class="line"><span class="string">        c += b.charAt(e);  # 去字符串中的xxx位置: 由上面假设, 此处就是 b</span></span><br><span class="line"><span class="string">    return c</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">function b(a, b) &#123;  # 参数a是要加密的内容, </span></span><br><span class="line"><span class="string">    var c = CryptoJS.enc.Utf8.parse(b)  # 所以 b 就是密钥</span></span><br><span class="line"><span class="string">      , d = CryptoJS.enc.Utf8.parse(&quot;0102030405060708&quot;)</span></span><br><span class="line"><span class="string">      , e = CryptoJS.enc.Utf8.parse(a)  # e是数据</span></span><br><span class="line"><span class="string">      , f = CryptoJS.AES.encrypt(e, c, &#123;  # AES加密算法? 这里的c就是加密的密钥</span></span><br><span class="line"><span class="string">        iv: d,  # AES加密里 iv 是偏移量</span></span><br><span class="line"><span class="string">        mode: CryptoJS.mode.CBC  # mode 是模式, 表示这里用的是 CBC 模式进行的加密</span></span><br><span class="line"><span class="string">    &#125;);</span></span><br><span class="line"><span class="string">    return f.toString()</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">function c(a, b, c) &#123;  # c里面不产生随机数</span></span><br><span class="line"><span class="string">    var d, e;</span></span><br><span class="line"><span class="string">    return setMaxDigits(131),</span></span><br><span class="line"><span class="string">    d = new RSAKeyPair(b,&quot;&quot;,c),</span></span><br><span class="line"><span class="string">    e = encryptedString(d, a)</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">function d(d, e, f, g) &#123;  # d: 数据 e: 010001 f: 很长的一个定值 g: &#x27;0CoJUm6Qyw8W8jud&#x27;</span></span><br><span class="line"><span class="string">    var h = &#123;&#125;  # 空对象</span></span><br><span class="line"><span class="string">      , i = a(16);  # i 就是一个16位的随机值, 可以把i设置成定值, 那么 encSecKey 就也是定的</span></span><br><span class="line"><span class="string">    h.encText = b(d, g),  # 分析函数b, 可以得出g是密钥</span></span><br><span class="line"><span class="string">    h.encText = b(h.encText, i),  # 返回的就是 params, i也是密钥</span></span><br><span class="line"><span class="string">    h.encSecKey = c(i, e, f),  # 返回的就是 encSecKey</span></span><br><span class="line"><span class="string">    # 分析 encSecKey, 参数e和f都是定死的, i是随机的, 如果此时固定i, 那么从c的函数中可以看出其不产生随机数, 那么最后得到的 encSecKey 一定也是定死的</span></span><br><span class="line"><span class="string">    return h</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    # 现在分析 params, 进行了两次的加密</span></span><br><span class="line"><span class="string">    # 数据+g =&gt; b =&gt; 第一次加密的结果+i =&gt; b = params</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 发送请求, 得到评论</span></span><br><span class="line">    resp = requests.post(url, data=&#123;</span><br><span class="line">        <span class="string">&quot;params&quot;</span>: get_params(json.dumps(data)),</span><br><span class="line">        <span class="string">&quot;encSecKey&quot;</span>: get_encSecKey()</span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="built_in">print</span>(resp.text)</span><br></pre></td></tr></table></figure>

<ul>
<li>结果，成功：</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1696420016729.png" alt="1696420016729"></p>
<h2 id="5-python-并发编程"><a href="#5-python-并发编程" class="headerlink" title="5. python 并发编程"></a>5. python 并发编程</h2><h3 id="5-1-简介"><a href="#5-1-简介" class="headerlink" title="5.1 简介"></a>5.1 简介</h3><ul>
<li>引入并发，就是为了提升程序的运行速度</li>
<li>程序提速的方法：<ul>
<li><strong>单线程串行</strong>：不加改造的程序</li>
<li><strong>多线程并发</strong>：py 的 threading 模块</li>
<li><strong>多 CPU 并行</strong>：multiprocessing</li>
<li><strong>多机器并行</strong>：hadoop&#x2F;hive&#x2F;spark</li>
</ul>
</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1697174911332.png" alt="1697174911332"></p>
<ul>
<li>python 对并发编程的支持<ul>
<li>多线程：<strong>threading</strong>，利用 CPU 和 IO 可以同时执行的原理，让 CPU 不会干巴巴等待 IO 完成</li>
<li>多进程：<strong>multiprocessing</strong>，利用多核 CPU 的能力，真正的并行执行任务</li>
<li>异步 IO：<strong>asyncio</strong>，在单线程利用 CPU 和 IO 同时执行的原理，实现函数异步执行</li>
<li>使用 <strong>Lock</strong> 对资源加锁，防止冲突访问</li>
<li>使用 <strong>Queue</strong> 实现不同线程&#x2F;进程之间的数据通信，实现<strong>生产者(边爬取)-消费者(边解析)模式</strong></li>
<li>使用<strong>线程池Pool&#x2F;进程池Pool</strong>，简化线程&#x2F;进程的任务提交、等待结束、获取结果</li>
<li>使用 <strong>subprocess</strong> 启动外部程序的进程，并进行输入输出交互</li>
</ul>
</li>
</ul>
<h3 id="5-2-如何选择多线程多进程多协程"><a href="#5-2-如何选择多线程多进程多协程" class="headerlink" title="5.2 如何选择多线程多进程多协程"></a>5.2 如何选择多线程多进程多协程</h3><blockquote>
<p>python 并发编程有三种方式：多线程 Thread、多进程 Process、多协程Coroutine</p>
</blockquote>
<h4 id="5-2-1-什么是-CPU-密集型计算、IO-密集型计算"><a href="#5-2-1-什么是-CPU-密集型计算、IO-密集型计算" class="headerlink" title="5.2.1 什么是 CPU 密集型计算、IO 密集型计算"></a>5.2.1 什么是 CPU 密集型计算、IO 密集型计算</h4><p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1697175455216.png" alt="1697175455216"></p>
<h4 id="5-2-2-多线程多进程多协程的对比"><a href="#5-2-2-多线程多进程多协程的对比" class="headerlink" title="5.2.2 多线程多进程多协程的对比"></a>5.2.2 多线程多进程多协程的对比</h4><p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1697175588626.png" alt="1697175588626"></p>
<h4 id="5-2-3-如何选择对应技术"><a href="#5-2-3-如何选择对应技术" class="headerlink" title="5.2.3 如何选择对应技术"></a>5.2.3 如何选择对应技术</h4><ul>
<li>python 速度慢的原因：<ul>
<li>动态类型语言，边解释边执行</li>
<li>GIL(全局解释器锁)，无法利用多核CPU并发执行</li>
</ul>
</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1697175628421.png" alt="1697175628421"></p>
<h3 id="5-3-python-利用多线程加速爬虫"><a href="#5-3-python-利用多线程加速爬虫" class="headerlink" title="5.3 python 利用多线程加速爬虫"></a>5.3 python 利用多线程加速爬虫</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">urls = [</span><br><span class="line">    <span class="string">f&quot;https://www.cnblogs.com/#p<span class="subst">&#123;page&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">50</span>+<span class="number">1</span>)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">craw</span>(<span class="params">url</span>):</span><br><span class="line">    r = requests.get(url)</span><br><span class="line">    <span class="built_in">print</span>(url, <span class="built_in">len</span>(r.text))</span><br><span class="line"></span><br><span class="line">craw(urls[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<ul>
<li>多线程</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> blog_spider</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">single_thread</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;single_thread begin&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> blog_spider.urls:</span><br><span class="line">        blog_spider.craw(url)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;single_thread end&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">multi_thread</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;multi_thread begin&quot;</span>)</span><br><span class="line">    threads = []</span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> blog_spider.urls:</span><br><span class="line">        threads.append(  <span class="comment"># 创建多线程, 每个线程传入函数和函数所需参数</span></span><br><span class="line">            threading.Thread(target=blog_spider.craw, args=(url,))</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> thread <span class="keyword">in</span> threads:  <span class="comment"># 启动</span></span><br><span class="line">        thread.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> thread <span class="keyword">in</span> threads:  <span class="comment"># 等待结束</span></span><br><span class="line">        thread.join()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;multi_thread end&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    start = time.time()</span><br><span class="line">    single_thread()</span><br><span class="line">    end = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;single_thread cost: &quot;</span>, end-start, <span class="string">&quot;seconds&quot;</span>)</span><br><span class="line"></span><br><span class="line">    start = time.time()</span><br><span class="line">    multi_thread()</span><br><span class="line">    end = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;multi_thread cost: &quot;</span>, end - start, <span class="string">&quot;seconds&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="5-4-实现生产者消费者模式的多线程爬虫"><a href="#5-4-实现生产者消费者模式的多线程爬虫" class="headerlink" title="5.4 实现生产者消费者模式的多线程爬虫"></a>5.4 实现生产者消费者模式的多线程爬虫</h3><h4 id="5-4-1-多组件的-Pipeline-技术架构"><a href="#5-4-1-多组件的-Pipeline-技术架构" class="headerlink" title="5.4.1 多组件的 Pipeline 技术架构"></a>5.4.1 多组件的 Pipeline 技术架构</h4><ul>
<li>复杂的事情一般会分很多中间步骤一步步完成</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1697178699318.png" alt="1697178699318"></p>
<h4 id="5-4-2-生产者消费者爬虫的架构"><a href="#5-4-2-生产者消费者爬虫的架构" class="headerlink" title="5.4.2 生产者消费者爬虫的架构"></a>5.4.2 生产者消费者爬虫的架构</h4><p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1697178748014.png" alt="1697178748014"></p>
<h4 id="5-4-3-多线程数据通信的-queue-Queue"><a href="#5-4-3-多线程数据通信的-queue-Queue" class="headerlink" title="5.4.3 多线程数据通信的 queue.Queue"></a>5.4.3 多线程数据通信的 queue.Queue</h4><ul>
<li>queue.Queue 可以用于多线程之间的、<strong>线程安全</strong>的数据通信</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> queue</span><br><span class="line"><span class="keyword">import</span> blog_spider</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">do_craw</span>(<span class="params">url_queue:queue.Queue, html_queue:queue.Queue</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    生产者</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        url = url_queue.get()</span><br><span class="line">        html = blog_spider.craw(url)</span><br><span class="line">        html_queue.put(html)</span><br><span class="line">        <span class="built_in">print</span>(threading.current_thread().name, <span class="string">f&quot;craw <span class="subst">&#123;url&#125;</span>&quot;</span>,</span><br><span class="line">              <span class="string">&quot;url_queue.size=&quot;</span>, url_queue.qsize())</span><br><span class="line">        time.sleep(random.randint(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">do_parse</span>(<span class="params">html_queue:queue.Queue, fout</span>):</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        html = html_queue.get()</span><br><span class="line">        results = blog_spider.parse(html)</span><br><span class="line">        <span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">            fout.write(<span class="built_in">str</span>(result) + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(threading.current_thread().name, <span class="string">f&quot;results <span class="subst">&#123;results&#125;</span>&quot;</span>,</span><br><span class="line">              <span class="string">&quot;html_queue.size=&quot;</span>, html_queue.qsize())</span><br><span class="line">        time.sleep(random.randint(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    url_queue = queue.Queue()</span><br><span class="line">    html_queue = queue.Queue()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> blog_spider.urls:</span><br><span class="line">        url_queue.put(url)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建三个生产者线程</span></span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        t = threading.Thread(target=do_craw, args=(url_queue, html_queue),</span><br><span class="line">                             name=<span class="string">f&quot;craw<span class="subst">&#123;idx&#125;</span>&quot;</span>)</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建两个消费者线程</span></span><br><span class="line">    fout = <span class="built_in">open</span>(<span class="string">&quot;02.data.txt&quot;</span>, <span class="string">&quot;w&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        t = threading.Thread(target=do_parse, args=(html_queue, fout),</span><br><span class="line">                             name=<span class="string">f&quot;parse<span class="subst">&#123;idx&#125;</span>&quot;</span>)</span><br><span class="line">        t.start()</span><br></pre></td></tr></table></figure>

<h3 id="5-5-线程安全问题以及-Lock-解决方案"><a href="#5-5-线程安全问题以及-Lock-解决方案" class="headerlink" title="5.5 线程安全问题以及 Lock 解决方案"></a>5.5 线程安全问题以及 Lock 解决方案</h3><ul>
<li><p><strong>线程安全</strong>：指某个函数、函数库在多线程环境中被调用时，能够正确的处理多个线程之间的共享变量，使程序功能正确完成</p>
</li>
<li><p><strong>线程不安全</strong>：由于线程的执行随时会发生切换，造成不可预料的结果</p>
</li>
<li><p><strong>Lock 用于解决线程安全问题</strong>：<code>lock = threading.Lock()</code></p>
<ul>
<li>用法一：<code>try-finally</code> 模式</li>
<li>用法二：<code>with</code> 模式</li>
</ul>
</li>
<li><p><strong>代码示例</strong>：</p>
<ul>
<li>错误示范：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Account</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, balance</span>):</span><br><span class="line">        self.balance = balance</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw</span>(<span class="params">account, amount</span>):</span><br><span class="line">    <span class="keyword">if</span> account.balance &gt;= amount:</span><br><span class="line">        time.sleep(<span class="number">0.1</span>)</span><br><span class="line">        <span class="built_in">print</span>(threading.current_thread().name,</span><br><span class="line">              <span class="string">&quot;取钱成功&quot;</span>)</span><br><span class="line"></span><br><span class="line">        account.balance -= amount</span><br><span class="line">        <span class="built_in">print</span>(threading.current_thread().name,</span><br><span class="line">              <span class="string">&quot;余额: &quot;</span>, account.balance)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(threading.current_thread().name,</span><br><span class="line">              <span class="string">&quot;取钱失败, 余额不足&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    account = Account(<span class="number">1000</span>)</span><br><span class="line">    ta = threading.Thread(name=<span class="string">&quot;ta&quot;</span>, target=draw, args=(account, <span class="number">800</span>))</span><br><span class="line">    tb = threading.Thread(name=<span class="string">&quot;tb&quot;</span>, target=draw, args=(account, <span class="number">800</span>))</span><br><span class="line"></span><br><span class="line">    ta.start()</span><br><span class="line">    tb.start()</span><br></pre></td></tr></table></figure>

<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1697246248156.png" alt="1697246248156"></p>
<ul>
<li>正确示范：加上 lock</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">lock = threading.Lock()</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Account</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, balance</span>):</span><br><span class="line">        self.balance = balance</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw</span>(<span class="params">account, amount</span>):</span><br><span class="line">    <span class="keyword">with</span> lock:</span><br><span class="line">        <span class="keyword">if</span> account.balance &gt;= amount:</span><br><span class="line">            time.sleep(<span class="number">0.1</span>)</span><br><span class="line">            <span class="built_in">print</span>(threading.current_thread().name,</span><br><span class="line">                  <span class="string">&quot;取钱成功&quot;</span>)</span><br><span class="line"></span><br><span class="line">            account.balance -= amount</span><br><span class="line">            <span class="built_in">print</span>(threading.current_thread().name,</span><br><span class="line">                  <span class="string">&quot;余额: &quot;</span>, account.balance)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(threading.current_thread().name,</span><br><span class="line">                  <span class="string">&quot;取钱失败, 余额不足&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    account = Account(<span class="number">1000</span>)</span><br><span class="line">    ta = threading.Thread(name=<span class="string">&quot;ta&quot;</span>, target=draw, args=(account, <span class="number">800</span>))</span><br><span class="line">    tb = threading.Thread(name=<span class="string">&quot;tb&quot;</span>, target=draw, args=(account, <span class="number">800</span>))</span><br><span class="line"></span><br><span class="line">    ta.start()</span><br><span class="line">    tb.start()</span><br></pre></td></tr></table></figure>

<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1697246351713.png" alt="1697246351713"></p>
</li>
</ul>
<h3 id="5-6-好用的线程池-ThreadPoolExecutor"><a href="#5-6-好用的线程池-ThreadPoolExecutor" class="headerlink" title="5.6 好用的线程池 ThreadPoolExecutor"></a>5.6 好用的线程池 ThreadPoolExecutor</h3><ul>
<li><strong>线程池的原理</strong>：</li>
</ul>
<p><img src="/../img/Spider%E5%85%A5%E9%97%A8.assets/1697246476661.png" alt="1697246476661"></p>
<ul>
<li><strong>使用线程池的好处</strong>：<ul>
<li>提升性能：减去大量新建、终止线程的开销，重用了线程资源</li>
<li>适用场景：适合处理突发性大量请求或需要大量线程完成任务，但实际任务处理时间较短</li>
<li>防御功能：能有效避免系统因为创建线程过多，而导致系统负荷过大相应变慢等问题</li>
</ul>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://tangsmallrong.github.io">thr</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://tangsmallrong.github.io/2023/11/18/Spider/">https://tangsmallrong.github.io/2023/11/18/Spider/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://tangsmallrong.github.io" target="_blank">thr's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/spider/">spider</a></div><div class="post_share"></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/11/18/Spring/" title="Spring"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Spring</div></div></a></div><div class="next-post pull-right"><a href="/2023/11/18/Xshell%E8%BF%9E%E4%B8%8D%E4%B8%8A%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8/" title="关于 XShell 连不上远程 CentOS7 云服务器的问题"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">关于 XShell 连不上远程 CentOS7 云服务器的问题</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%88%AC%E8%99%AB"><span class="toc-text">爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E4%BB%8B%E7%BB%8D"><span class="toc-text">1. 相关概念介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E7%88%AC%E8%99%AB%E6%A0%B8%E5%BF%83%EF%BC%9F"><span class="toc-text">1.1 爬虫核心？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E7%88%AC%E8%99%AB%E7%9A%84%E7%94%A8%E9%80%94"><span class="toc-text">1.2 爬虫的用途</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-%E7%88%AC%E8%99%AB%E5%88%86%E7%B1%BB"><span class="toc-text">1.3 爬虫分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-%E5%8F%8D%E7%88%AC%E6%89%8B%E6%AE%B5"><span class="toc-text">1.4 反爬手段</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-urllib-%E5%BA%93%E4%BD%BF%E7%94%A8"><span class="toc-text">2. urllib 库使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="toc-text">2.1 基本使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E4%B8%80%E4%B8%AA%E7%B1%BB%E5%9E%8B%EF%BC%8C%E5%85%AD%E4%B8%AA%E6%96%B9%E6%B3%95"><span class="toc-text">2.2 一个类型，六个方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E4%B8%8B%E8%BD%BD"><span class="toc-text">2.3 下载</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-%E8%AF%B7%E6%B1%82%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%AE%9A%E5%88%B6"><span class="toc-text">2.4 请求对象的定制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-%E7%BC%96%E8%A7%A3%E7%A0%81"><span class="toc-text">2.5 编解码</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-5-1-get-%E8%AF%B7%E6%B1%82%E7%9A%84-quote-%E6%96%B9%E6%B3%95"><span class="toc-text">2.5.1 get 请求的 quote 方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-5-2-get-%E8%AF%B7%E6%B1%82%E7%9A%84-urlencode-%E6%96%B9%E6%B3%95"><span class="toc-text">2.5.2 get 请求的 urlencode 方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-5-3-post-%E8%AF%B7%E6%B1%82%E6%96%B9%E5%BC%8F"><span class="toc-text">2.5.3 post 请求方式</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-6-Ajax-%E8%AF%B7%E6%B1%82"><span class="toc-text">2.6 Ajax 请求</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-6-1-get-%E8%AF%B7%E6%B1%82"><span class="toc-text">2.6.1 get 请求</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-6-2-post-%E8%AF%B7%E6%B1%82"><span class="toc-text">2.6.2 post 请求</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-7-URLError-HTTPError"><span class="toc-text">2.7 URLError\HTTPError</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-8-cookie-%E7%99%BB%E5%BD%95"><span class="toc-text">2.8 cookie 登录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-9-Handler-%E5%A4%84%E7%90%86%E5%99%A8"><span class="toc-text">2.9 Handler 处理器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-10-%E4%BB%A3%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8"><span class="toc-text">2.10 代理服务器</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%A7%A3%E6%9E%90"><span class="toc-text">解析</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-xpath"><span class="toc-text">1. xpath</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-xpath-%E6%8F%92%E4%BB%B6%E5%AE%89%E8%A3%85"><span class="toc-text">1.1 xpath 插件安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-xpath-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="toc-text">1.2 xpath 基本使用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-1-lxml-%E5%BA%93%E7%9A%84%E5%AE%89%E8%A3%85"><span class="toc-text">1.2.1 lxml 库的安装</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-2-xpath-%E8%A7%A3%E6%9E%90"><span class="toc-text">1.2.2 xpath 解析</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-%E8%8E%B7%E5%8F%96%E7%99%BE%E5%BA%A6%E9%A1%B5%E9%9D%A2%E7%9A%84-%E7%99%BE%E5%BA%A6%E4%B8%80%E4%B8%8B-%E5%9B%9B%E4%B8%AA%E5%AD%97"><span class="toc-text">1.3 获取百度页面的 百度一下 四个字</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-%E7%AB%99%E9%95%BF%E7%B4%A0%E6%9D%90-%E5%90%AB%E6%87%92%E5%8A%A0%E8%BD%BD%E3%80%81%E5%A6%82%E4%BD%95%E4%B8%8B%E8%BD%BD%E5%85%B6%E4%B8%AD%E7%9A%84%E9%AB%98%E6%B8%85%E5%9B%BE"><span class="toc-text">1.4 站长素材(含懒加载、如何下载其中的高清图)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-JsonPath"><span class="toc-text">2. JsonPath</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D"><span class="toc-text">2.1 基本介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-1-%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8"><span class="toc-text">2.1.1 安装及使用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-2-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95-%E4%B8%8E-xpath-%E5%AF%B9%E6%AF%94"><span class="toc-text">2.1.2 基本语法(与 xpath 对比)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-3-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="toc-text">2.1.3 基本使用</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-JsonPath-%E8%A7%A3%E6%9E%90%E6%B7%98%E7%A5%A8%E7%A5%A8"><span class="toc-text">2.2 JsonPath 解析淘票票</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-BeautifulSoup-%E5%8D%B3bs4"><span class="toc-text">3. BeautifulSoup(即bs4)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="toc-text">3.1 基本使用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-1-%E7%AE%80%E4%BB%8B"><span class="toc-text">3.1.1 简介</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-2-%E5%AE%89%E8%A3%85%E5%8F%8A%E5%88%9B%E5%BB%BA"><span class="toc-text">3.1.2 安装及创建</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-3-%E8%8A%82%E7%82%B9%E5%AE%9A%E4%BD%8D"><span class="toc-text">3.1.3 节点定位</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-4-%E8%8A%82%E7%82%B9%E4%BF%A1%E6%81%AF"><span class="toc-text">3.1.4 节点信息</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-5-%E4%BB%A3%E7%A0%81%E6%BC%94%E7%A4%BA"><span class="toc-text">3.1.5 代码演示</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-bs4-%E7%88%AC%E5%8F%96%E6%98%9F%E5%B7%B4%E5%85%8B%E6%95%B0%E6%8D%AE"><span class="toc-text">3.2 bs4 爬取星巴克数据</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Selenium"><span class="toc-text">Selenium</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Selenium"><span class="toc-text">1. Selenium</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E4%BB%8B%E7%BB%8D"><span class="toc-text">1.1 介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="toc-text">1.2 基本使用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-1-%E5%AE%89%E8%A3%85-selenium"><span class="toc-text">1.2.1 安装 selenium</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-2-%E7%89%88%E6%9C%AC%E5%85%BC%E5%AE%B9%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3"><span class="toc-text">1.2.2 版本兼容问题解决</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-3-%E4%BB%A3%E7%A0%81%E6%BC%94%E7%A4%BA"><span class="toc-text">1.2.3 代码演示</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-%E5%85%83%E7%B4%A0%E5%AE%9A%E4%BD%8D"><span class="toc-text">1.3 元素定位</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-1-%E5%85%83%E7%B4%A0%E5%AE%9A%E4%BD%8D%E7%9A%84%E5%AE%9A%E4%B9%89%E4%B8%8E%E6%96%B9%E6%B3%95"><span class="toc-text">1.3.1 元素定位的定义与方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-2-%E4%BB%A3%E7%A0%81%E6%BC%94%E7%A4%BA"><span class="toc-text">1.3.2 代码演示</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-%E5%85%83%E7%B4%A0%E4%BF%A1%E6%81%AF"><span class="toc-text">1.4 元素信息</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-1-%E8%AE%BF%E9%97%AE%E5%85%83%E7%B4%A0%E4%BF%A1%E6%81%AF"><span class="toc-text">1.4.1 访问元素信息</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-2-%E4%BB%A3%E7%A0%81%E6%BC%94%E7%A4%BA"><span class="toc-text">1.4.2 代码演示</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-5-selenium-%E7%9A%84%E4%BA%A4%E4%BA%92"><span class="toc-text">1.5 selenium 的交互</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-5-1-%E4%BA%A4%E4%BA%92"><span class="toc-text">1.5.1 交互</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-5-2-%E4%BB%A3%E7%A0%81%E6%BC%94%E7%A4%BA"><span class="toc-text">1.5.2 代码演示</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Phantomjs"><span class="toc-text">2. Phantomjs</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E4%BB%8B%E7%BB%8D"><span class="toc-text">2.1 介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8-Phantomjs"><span class="toc-text">2.2 如何使用 Phantomjs</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Chrome-handless"><span class="toc-text">3. Chrome handless</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#requests"><span class="toc-text">requests</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="toc-text">1. 基本使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-get-%E8%AF%B7%E6%B1%82"><span class="toc-text">2. get 请求</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-post-%E8%AF%B7%E6%B1%82"><span class="toc-text">3. post 请求</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E4%BB%A3%E7%90%86"><span class="toc-text">4. 代理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-cookie-%E5%AE%9A%E5%88%B6"><span class="toc-text">5. cookie 定制</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#scrapy"><span class="toc-text">scrapy</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-srcapy-%E5%AE%89%E8%A3%85"><span class="toc-text">1. srcapy 安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E4%BB%80%E4%B9%88%E6%98%AF-srcapy"><span class="toc-text">1.1 什么是 srcapy</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-srcapy-%E7%9A%84%E5%AE%89%E8%A3%85"><span class="toc-text">1.2 srcapy 的安装</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="toc-text">2. 基本使用</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%A1%A5%E5%85%85%E7%9F%A5%E8%AF%86"><span class="toc-text">补充知识</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95"><span class="toc-text">1. 模拟登录</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-sign-%E5%8F%8D%E7%88%AC-js-%E9%80%86%E5%90%91"><span class="toc-text">2. sign 反爬-js 逆向</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E6%B5%8F%E8%A7%88%E5%99%A8%E8%B0%83%E8%AF%95-Dev-Tools"><span class="toc-text">3. 浏览器调试 Dev Tools</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E5%90%84%E4%B8%AA-Tab-%E4%BB%8B%E7%BB%8D"><span class="toc-text">3.1 各个 Tab 介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E6%8E%A7%E5%88%B6%E5%8F%B0-Console"><span class="toc-text">3.2 控制台(Console)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-JS-%E8%B0%83%E8%AF%95"><span class="toc-text">3.3 JS 调试</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-Network"><span class="toc-text">3.4 Network</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%A1%88%E4%BE%8B%EF%BC%9A%E6%8A%93%E5%8F%96%E7%BD%91%E6%98%93%E4%BA%91%E8%AF%84%E8%AE%BA"><span class="toc-text">4. 案例：抓取网易云评论</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E5%88%86%E6%9E%90%E6%8E%A5%E5%8F%A3"><span class="toc-text">4.1 分析接口</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E9%80%86%E5%90%91-js"><span class="toc-text">4.2 逆向 js</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E5%AF%B9%E5%8A%A0%E5%AF%86%E8%BF%87%E7%A8%8B%E8%BF%9B%E8%A1%8C%E5%88%86%E6%9E%90"><span class="toc-text">4.3 对加密过程进行分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-%E7%BC%96%E5%86%99%E4%BB%A3%E7%A0%81%EF%BC%8C%E5%BE%97%E5%88%B0%E7%BB%93%E6%9E%9C"><span class="toc-text">4.4 编写代码，得到结果</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-python-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B"><span class="toc-text">5. python 并发编程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E7%AE%80%E4%BB%8B"><span class="toc-text">5.1 简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%A4%9A%E5%8D%8F%E7%A8%8B"><span class="toc-text">5.2 如何选择多线程多进程多协程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-1-%E4%BB%80%E4%B9%88%E6%98%AF-CPU-%E5%AF%86%E9%9B%86%E5%9E%8B%E8%AE%A1%E7%AE%97%E3%80%81IO-%E5%AF%86%E9%9B%86%E5%9E%8B%E8%AE%A1%E7%AE%97"><span class="toc-text">5.2.1 什么是 CPU 密集型计算、IO 密集型计算</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-2-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%A4%9A%E5%8D%8F%E7%A8%8B%E7%9A%84%E5%AF%B9%E6%AF%94"><span class="toc-text">5.2.2 多线程多进程多协程的对比</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-3-%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%AF%B9%E5%BA%94%E6%8A%80%E6%9C%AF"><span class="toc-text">5.2.3 如何选择对应技术</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-python-%E5%88%A9%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%8A%A0%E9%80%9F%E7%88%AC%E8%99%AB"><span class="toc-text">5.3 python 利用多线程加速爬虫</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-%E5%AE%9E%E7%8E%B0%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%88%AC%E8%99%AB"><span class="toc-text">5.4 实现生产者消费者模式的多线程爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-4-1-%E5%A4%9A%E7%BB%84%E4%BB%B6%E7%9A%84-Pipeline-%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84"><span class="toc-text">5.4.1 多组件的 Pipeline 技术架构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-4-2-%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E7%88%AC%E8%99%AB%E7%9A%84%E6%9E%B6%E6%9E%84"><span class="toc-text">5.4.2 生产者消费者爬虫的架构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-4-3-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1%E7%9A%84-queue-Queue"><span class="toc-text">5.4.3 多线程数据通信的 queue.Queue</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-5-%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E9%97%AE%E9%A2%98%E4%BB%A5%E5%8F%8A-Lock-%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-text">5.5 线程安全问题以及 Lock 解决方案</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-6-%E5%A5%BD%E7%94%A8%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%B1%A0-ThreadPoolExecutor"><span class="toc-text">5.6 好用的线程池 ThreadPoolExecutor</span></a></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By thr</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>